# -*- coding: utf-8 -*-
"""Refactored_Football_Prediction_Code_21_4_2024v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r-3ZMlRoIRQI4p8SKmmrZZrJiFrohTtS
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install python-dotenv pandas numpy pymc arviz tensorflow requests tqdm matplotlib plotly colorama gradio shap joblib

!pip install uvicorn

!pip install streamlit

# -*- coding: utf-8 -*-
"""
Uudelleenjärjestelty jalkapalloennustejärjestelmä Google Colabille

Tämä skripti toteuttaa jalkapallo-otteluiden ennustejärjestelmän, joka sisältää:
- Datan hakemisen football-data.org- ja API-FOOTBALL-rajapinnoista välimuistilla.
- ELO-pisteiden laskennan.
- Vektorisoidun ominaisuusmuokkauksen (kunto, lepopäivät, keskinäiset ottelut).
- Yhtenäisen esikäsittelyn dedikoidulla luokalla.
- Bayesilaisen mallinnuksen PyMC:llä (Negatiivinen Binomi -todennäköisyys).
- Neuroverkkopohjaisen mallinnuksen TensorFlow/Kerasilla (Poisson-häviö).
- Ennusteputken mallivalinnalla ja varamallilla.
- Walk-forward-jälkitestauksen ja suorituskykymittarit.
- Raportoinnin ja visualisoinnit.
- Gradio-käyttöliittymän interaktiivisille ennusteille.

Korjaukset:
- Poistettu päällekkäiset metodimäärittelyt FeaturePreprocessor-luokassa.
- Korjattu IndentationError _calculate_h2h_vectorized-metodissa.
- Yksinkertaistettu run_prediction_pipeline ja poistettu kaksoismäärittelyt.
- Integroitu optimoitu Gradio UI -toteutus.
- Lisätty pickle-import ELO-historian tallennukseen.
- Korjattu H2H-laskennan MultiIndex-virhe merkkijonopohjaisella team_pair-avaimella.
- Lisätty riippuvuuksien asennus Colab-ympäristöön.
- Sisältää epävarmuuskäsittelyn ja muita parannuksia.
"""

# --- Asenna tarvittavat riippuvuudet ---
!pip install python-dotenv pandas numpy pymc arviz tensorflow requests tqdm matplotlib plotly colorama gradio shap joblib

# --- Ydinbiblioteekit ---
import pandas as pd
import numpy as np
import pymc as pm
import arviz as az
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
import requests
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from google.colab import drive, userdata
import logging
from logging.handlers import RotatingFileHandler
import os
import glob
from datetime import datetime, timedelta
import time
import json
import argparse
import sys
import pickle
from typing import Tuple, List, Dict, Optional, Any

# --- ML/tilastobiblioteekit ---
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import brier_score_loss, log_loss, accuracy_score, mean_absolute_error
from sklearn.calibration import calibration_curve
from scipy.stats import poisson, nbinom
from collections import Counter
import joblib
import shap

# --- Apubiblioteekit ---
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv
from tqdm import tqdm
import matplotlib.pyplot as plt
import plotly.express as px
from colorama import Fore, init
from numba import jit
import gradio as gr

# --- Alustus ---
init(autoreset=True)

# --- Konfiguraatioluokka ---
class Config:
    """Sisältää kaikki järjestelmän konfiguraatioparametrit."""
    SAMPLING_MODE: str = "normal"
    USE_NN: bool = True
    USE_NEGBIN: bool = True
    SAMPLING_PARAMS: Dict[str, Dict[str, int]] = {
        "fast": {"draws": 500, "tune": 500, "chains": 2},
        "normal": {"draws": 2000, "tune": 1000, "chains": 4},
        "advi": {"n": 10000}
    }
    NN_EPOCHS: int = 100
    NN_BATCH_SIZE: int = 32
    NN_VALIDATION_SPLIT: float = 0.2
    NN_EARLY_STOPPING_PATIENCE: int = 10
    MC_DROPOUT_SAMPLES: int = 50

    K_FACTOR: float = 32.0
    INITIAL_ELO: float = 1500.0
    INITIAL_TOP_ELO: float = 1600.0
    TOP_TEAMS: List[str] = ["Manchester City FC", "Arsenal FC", "Liverpool FC", "Chelsea FC"]

    DEFAULT_LEAGUE_CODE: str = "PL"
    DEFAULT_LEAGUE_ID: int = 39
    FEATURE_FORM_WINDOW: int = 5
    FEATURE_H2H_WINDOW: int = 5
    FEATURE_CLIP_MIN: float = -5.0
    FEATURE_CLIP_MAX: float = 5.0
    NUMERIC_FEATURES_TO_SCALE: List[str] = [
        "form_home", "form_away", "rest_days_home", "rest_days_away", "h2h",
        "rank_pts_per_game_home", "rank_pts_per_game_away", "ppg_home", "ppg_away"
    ]
    MODEL_FEATURE_COLUMNS: List[str] = [
        "form_home", "form_away", "rest_days_home", "rest_days_away", "h2h",
        "rank_pts_per_game_home", "rank_pts_per_game_away", "ppg_home", "ppg_away",
        "elo_diff", "form_diff", "rank_diff"
    ]

    DRIVE_MOUNT_POINT: str = "/content/drive"
    BASE_DATA_FOLDER: str = "AI_FUTIS_DATA"
    BASE_PREDICTION_FOLDER: str = "AI_FUTIS_PREDICTIONS"
    SUBFOLDERS: List[str] = ["CACHE", "PDF", "CSV", "PLOTS", "MODELS"]
    LOG_FILE_NAME: str = "football_predictions.log"
    CACHE_EXPIRY_DAYS: int = 1

    API_KEY_FOOTBALL_DATA: Optional[str] = None
    API_KEY_API_FOOTBALL: Optional[str] = None
    OPENWEATHER_API_KEY: Optional[str] = None

    BACKTEST_TRAIN_SPLIT_RATIO: float = 0.70
    BACKTEST_RETRAIN_STEP: int = 50
    ENABLE_GRADIO_UI: bool = True

    data_folder: str = ""
    prediction_folder: str = ""
    log_file_path: str = ""
    cache_folder: str = ""
    model_folder: str = ""

    def setup_paths_and_logging(self):
        drive_mounted = False
        try:
            if not os.path.exists(self.DRIVE_MOUNT_POINT) or not os.path.ismount(self.DRIVE_MOUNT_POINT):
                print(Fore.YELLOW + f"Liitetään Google Drive osoitteeseen {self.DRIVE_MOUNT_POINT}...")
                drive.mount(self.DRIVE_MOUNT_POINT, force_remount=True)
                drive_base = os.path.join(self.DRIVE_MOUNT_POINT, "MyDrive")
                drive_mounted = True
                print(Fore.GREEN + "Google Drive liitetty onnistuneesti.")
            else:
                drive_base = os.path.join(self.DRIVE_MOUNT_POINT, "MyDrive")
                drive_mounted = True
                print(Fore.YELLOW + "Google Drive on jo liitetty.")
        except Exception as e:
            print(Fore.RED + f"⚠️ VAROITUS: Google Drive -liitos epäonnistui: {e}. Käytetään paikallista /content/-hakemistoa.")
            drive_base = "/content"

        self.data_folder = os.path.join(drive_base, self.BASE_DATA_FOLDER)
        self.prediction_folder = os.path.join(drive_base, self.BASE_PREDICTION_FOLDER)
        self.cache_folder = os.path.join(self.data_folder, "CACHE")
        self.model_folder = os.path.join(self.prediction_folder, "MODELS")

        os.makedirs(self.data_folder, exist_ok=True)
        os.makedirs(self.prediction_folder, exist_ok=True)
        os.makedirs(self.cache_folder, exist_ok=True)
        os.makedirs(self.model_folder, exist_ok=True)

        for sub in self.SUBFOLDERS:
            if sub not in ["CACHE", "MODELS"]:
                os.makedirs(os.path.join(self.prediction_folder, sub), exist_ok=True)

        self.log_file_path = os.path.join(self.prediction_folder, self.LOG_FILE_NAME)
        log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
        log_handler = RotatingFileHandler(self.log_file_path, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
        log_handler.setFormatter(log_formatter)

        root_logger = logging.getLogger()
        if not any(isinstance(h, logging.StreamHandler) for h in root_logger.handlers):
            stream_handler = logging.StreamHandler(sys.stdout)
            stream_handler.setFormatter(log_formatter)
            root_logger.addHandler(stream_handler)

        for handler in root_logger.handlers[:]:
            if isinstance(handler, RotatingFileHandler) and handler.baseFilename == self.log_file_path:
                root_logger.removeHandler(handler)

        root_logger.addHandler(log_handler)
        root_logger.setLevel(logging.INFO)

        logging.getLogger("requests").setLevel(logging.WARNING)
        logging.getLogger("urllib3").setLevel(logging.WARNING)
        logging.getLogger("matplotlib").setLevel(logging.WARNING)
        logging.getLogger("PIL").setLevel(logging.WARNING)
        logging.getLogger("httpx").setLevel(logging.WARNING)

        logging.info(f"Lokitus alustettu. Lokitiedosto: {self.log_file_path}")
        logging.info(f"Datahakemisto: {self.data_folder}")
        logging.info(f"Ennustehakemisto: {self.prediction_folder}")
        logging.info(f"Drive liitetty: {drive_mounted}")

    def load_api_keys(self):
        load_dotenv()
        try:
            from google.colab import userdata
            self.API_KEY_FOOTBALL_DATA = userdata.get("football-data.org")
            self.API_KEY_API_FOOTBALL = userdata.get("API-FOOTBALL_API")
            self.OPENWEATHER_API_KEY = userdata.get("OpenWeather")
            logging.info("API-avaimet ladattu Colab Secrets -palvelusta.")
        except ImportError:
            logging.warning("google.colab.userdata ei saatavilla. Yritetään ympäristömuuttujia.")
            self.API_KEY_FOOTBALL_DATA = None
            self.API_KEY_API_FOOTBALL = None
            self.OPENWEATHER_API_KEY = None
        except Exception as e:
            logging.error(f"Virhe ladattaessa Colab Secrets: {e}")
            self.API_KEY_FOOTBALL_DATA = None
            self.API_KEY_API_FOOTBALL = None
            self.OPENWEATHER_API_KEY = None

        # Yritä ladata ympäristömuuttujista, jos Colab Secrets ei toimi
        if not self.API_KEY_FOOTBALL_DATA:
            self.API_KEY_FOOTBALL_DATA = os.getenv("FOOTBALL_DATA_API_KEY")
        if not self.API_KEY_API_FOOTBALL:
            self.API_KEY_API_FOOTBALL = os.getenv("API_FOOTBALL_API_KEY")
        if not self.OPENWEATHER_API_KEY:
            self.OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY")

        # Lokita avaimien tila
        if not self.API_KEY_FOOTBALL_DATA:
            logging.warning("Football-data.org API-avain puuttuu.")
        else:
            logging.info("Football-data.org API-avain ladattu.")
        if not self.API_KEY_API_FOOTBALL:
            logging.warning("API-FOOTBALL API-avain puuttuu.")
        else:
            logging.info("API-FOOTBALL API-avain ladattu.")
        if not self.OPENWEATHER_API_KEY:
            logging.warning("OpenWeatherMap API-avain puuttuu.")
        else:
            logging.info("OpenWeatherMap API-avain ladattu.")

class DataFetchError(Exception):
    pass

class ModelError(Exception):
    pass

class PreprocessingError(Exception):
    pass

def get_current_season() -> int:
    now = datetime.now()
    return now.year if now.month >= 7 else now.year - 1

def get_http_session(retries: int = 3, backoff_factor: float = 0.5,
                     status_forcelist: Tuple[int, ...] = (500, 502, 503, 504)) -> requests.Session:
    session = requests.Session()
    retry_strategy = Retry(
        total=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    return session

class DataHandler:
    def __init__(self, config: Config):
        self.config = config
        self.session = get_http_session()

    def _fetch_football_data(self, competition: str, season: int) -> Optional[pd.DataFrame]:
        if not self.config.API_KEY_FOOTBALL_DATA:
            logging.warning("Ohitetaan football-data.org haku: API-avain puuttuu.")
            return None
        url = f"https://api.football-data.org/v4/competitions/{competition}/matches?season={season}"
        headers = {"X-Auth-Token": self.config.API_KEY_FOOTBALL_DATA}
        try:
            response = self.session.get(url, headers=headers, timeout=20)
            response.raise_for_status()
            data = response.json()
            if "matches" in data and data["matches"]:
                logging.info(f"Haettiin {len(data['matches'])} ottelua liigalle {competition} kaudelle {season} football-data.org:sta")
                df = pd.json_normalize(data["matches"])
                required_cols = {'utcDate', 'status', 'matchday', 'homeTeam.name', 'awayTeam.name', 'score.fullTime.home', 'score.fullTime.away'}
                if not required_cols.issubset(df.columns):
                    logging.warning(f"football-data.org vastaus puuttuu vaadittuja sarakkeita liigalle {competition} kaudelle {season}. Löytyi: {list(df.columns)}")
                    return None
                return df
            else:
                logging.warning(f"Ei otteluita liigalle {competition} kaudelle {season} football-data.org:ssa.")
                return None
        except requests.exceptions.Timeout:
            logging.error(f"Aikakatkaisu haettaessa football-data.org liigalle {competition} kaudelle {season}")
            return None
        except requests.exceptions.HTTPError as e:
            logging.error(f"HTTP-virhe {e.response.status_code} haettaessa football-data.org liigalle {competition} kaudelle {season}: {e.response.reason}")
            return None
        except requests.RequestException as e:
            logging.error(f"RequestException haettaessa football-data.org liigalle {competition} kaudelle {season}: {e}")
            return None
        except json.JSONDecodeError as e:
            logging.error(f"JSON-dekoodausvirhe haettaessa football-data.org liigalle {competition} kaudelle {season}: {e}")
            return None

    def _fetch_api_football(self, league_id: int, season: int) -> Optional[pd.DataFrame]:
        if not self.config.API_KEY_API_FOOTBALL:
            logging.warning("Ohitetaan API-FOOTBALL haku: API-avain puuttuu.")
            return None
        url = "https://api-football-v1.p.rapidapi.com/v3/fixtures"
        querystring = {"league": str(league_id), "season": str(season)}
        headers = {
            "X-RapidAPI-Key": self.config.API_KEY_API_FOOTBALL,
            "X-RapidAPI-Host": "api-football-v1.p.rapidapi.com"
        }
        try:
            response = self.session.get(url, headers=headers, params=querystring, timeout=30)
            response.raise_for_status()
            data = response.json()
            if "response" in data and data["response"]:
                matches_data = data["response"]
                logging.info(f"Haettiin {len(matches_data)} ottelua liigalle {league_id} kaudelle {season} API-FOOTBALL:sta")
                processed_matches = []
                for match in matches_data:
                    fixture = match.get("fixture", {})
                    teams = match.get("teams", {})
                    goals = match.get("goals", {})
                    score = match.get("score", {})
                    fulltime_score = score.get("fulltime", {})
                    processed = {
                        "utcDate": fixture.get("date"),
                        "status_short": fixture.get("status", {}).get("short"),
                        "status_long": fixture.get("status", {}).get("long"),
                        "matchday": fixture.get("round"),
                        "homeTeam.name": teams.get("home", {}).get("name"),
                        "homeTeam.id_api_football": teams.get("home", {}).get("id"),
                        "awayTeam.name": teams.get("away", {}).get("name"),
                        "awayTeam.id_api_football": teams.get("away", {}).get("id"),
                        "score.fullTime.home": goals.get("home"),
                        "score.fullTime.away": goals.get("away"),
                        "score.fullTime.home_fallback": fulltime_score.get("home"),
                        "score.fullTime.away_fallback": fulltime_score.get("away"),
                        "fixture.id_api_football": fixture.get("id")
                    }
                    if processed["score.fullTime.home"] is None:
                        processed["score.fullTime.home"] = processed["score.fullTime.home_fallback"]
                    if processed["score.fullTime.away"] is None:
                        processed["score.fullTime.away"] = processed["score.fullTime.away_fallback"]
                    processed_matches.append(processed)
                df = pd.DataFrame(processed_matches)
                status_map = {
                    'TBD': 'SCHEDULED', 'NS': 'SCHEDULED', '1H': 'IN_PLAY', 'HT': 'IN_PLAY',
                    '2H': 'IN_PLAY', 'ET': 'IN_PLAY', 'P': 'IN_PLAY', 'FT': 'FINISHED',
                    'AET': 'FINISHED', 'PEN': 'FINISHED', 'BT': 'FINISHED',
                    'SUSP': 'SUSPENDED', 'INT': 'SUSPENDED',
                    'PST': 'POSTPONED', 'CANC': 'CANCELLED', 'ABD': 'CANCELLED',
                    'AWD': 'FINISHED', 'WO': 'FINISHED'
                }
                df['status'] = df['status_short'].map(status_map).fillna('UNKNOWN')
                return df
            else:
                logging.warning(f"Ei otteluita liigalle {league_id} kaudelle {season} API-FOOTBALL:ssa. Vastaus: {data.get('errors')}")
                return None
        except requests.exceptions.Timeout:
            logging.error(f"Aikakatkaisu haettaessa API-FOOTBALL liigalle {league_id} kaudelle {season}")
            return None
        except requests.exceptions.HTTPError as e:
            logging.error(f"HTTP-virhe {e.response.status_code} haettaessa API-FOOTBALL liigalle {league_id} kaudelle {season}: {e.response.reason}")
            return None
        except requests.RequestException as e:
            logging.error(f"RequestException haettaessa API-FOOTBALL liigalle {league_id} kaudelle {season}: {e}")
            return None
        except json.JSONDecodeError as e:
            logging.error(f"JSON-dekoodausvirhe haettaessa API-FOOTBALL liigalle {league_id} kaudelle {season}: {e}")
            return None

    def get_matches(self, league_code: str, league_id: int, seasons: List[int], force_refresh: bool = False) -> pd.DataFrame:
        all_dfs = []
        for season in seasons:
            cache_filename = f"matches_{league_code}_{season}.pkl"
            cache_path = os.path.join(self.config.cache_folder, cache_filename)
            if not force_refresh and os.path.exists(cache_path):
                try:
                    cache_mtime = datetime.fromtimestamp(os.path.getmtime(cache_path))
                    if (datetime.now() - cache_mtime).days < self.config.CACHE_EXPIRY_DAYS:
                        logging.info(f"Ladataan välimuistista: {cache_path}")
                        df = pd.read_pickle(cache_path)
                        if isinstance(df, pd.DataFrame) and not df.empty and 'utcDate' in df.columns:
                            logging.info(f"Ladattiin {len(df)} ottelua välimuistista.")
                            all_dfs.append(df)
                            continue
                        else:
                            logging.warning(f"Välimuistitiedosto {cache_path} tyhjä tai virheellinen. Haetaan uudelleen.")
                    else:
                        logging.info(f"Välimuistitiedosto {cache_path} vanhentunut. Haetaan uudelleen.")
                except Exception as e:
                    logging.error(f"Virhe ladattaessa välimuistitiedostoa {cache_path}: {e}. Haetaan uudelleen.")
            logging.info(f"Haetaan tuore data liigalle {league_code} kaudelle {season}...")
            df_fd = self._fetch_football_data(league_code, season)
            df_combined = pd.DataFrame()
            if df_fd is not None and not df_fd.empty:
                df_combined = df_fd
                logging.info(f"Käytetään ensisijaisesti football-data.org dataa liigalle {league_code} kaudelle {season}")
            else:
                logging.warning(f"Ensisijainen lähde (football-data.org) epäonnistui liigalle {league_code} kaudelle {season}. Yritetään API-FOOTBALL.")
                df_api = self._fetch_api_football(league_id, season)
                if df_api is not None and not df_api.empty:
                    df_combined = df_api
                    logging.info(f"Käytetään API-FOOTBALL dataa liigalle {league_code} kaudelle {season}")
                else:
                    logging.error(f"Molemmat lähteet epäonnistuivat liigalle {league_code} kaudelle {season}.")
                    continue
            df_combined['utcDate'] = pd.to_datetime(df_combined['utcDate'], utc=True, errors='coerce')
            df_combined = df_combined.dropna(subset=['utcDate', 'homeTeam.name', 'awayTeam.name'])
            df_combined['score.fullTime.home'] = pd.to_numeric(df_combined['score.fullTime.home'], errors='coerce')
            df_combined['score.fullTime.away'] = pd.to_numeric(df_combined['score.fullTime.away'], errors='coerce')
            if 'status' not in df_combined.columns:
                logging.warning("Sarake 'status' puuttuu haun jälkeen. Ei voida standardoida statusta.")
                df_combined['status'] = 'UNKNOWN'
            else:
                status_map_combined = {
                    'FINISHED': 'FINISHED', 'FT': 'FINISHED', 'AET': 'FINISHED', 'PEN': 'FINISHED',
                    'SCHEDULED': 'SCHEDULED', 'TIMED': 'SCHEDULED', 'NS': 'SCHEDULED', 'TBD': 'SCHEDULED',
                    'POSTPONED': 'POSTPONED', 'PST': 'POSTPONED',
                    'CANCELLED': 'CANCELLED', 'CANC': 'CANCELLED', 'ABD': 'CANCELLED',
                    'IN_PLAY': 'IN_PLAY', 'LIVE': 'IN_PLAY', '1H': 'IN_PLAY', 'HT': 'IN_PLAY', '2H': 'IN_PLAY', 'ET': 'IN_PLAY', 'P': 'IN_PLAY', 'BT': 'IN_PLAY',
                    'SUSPENDED': 'SUSPENDED', 'INT': 'SUSPENDED',
                }
                df_combined['status'] = df_combined['status'].map(status_map_combined).fillna(df_combined['status'])
            column_map = {
                'utcDate': 'utcDate',
                'status': 'status',
                'homeTeam.name': 'homeTeamName',
                'awayTeam.name': 'awayTeamName',
                'score.fullTime.home': 'homeGoals',
                'score.fullTime.away': 'awayGoals',
            }
            cols_to_keep = [col for col in column_map.keys() if col in df_combined.columns]
            df_final = df_combined[cols_to_keep].rename(columns=column_map)
            df_final['season'] = season
            df_final['league'] = league_code
            df_final = df_final.sort_values(by='utcDate').reset_index(drop=True)
            try:
                df_final.to_pickle(cache_path)
                logging.info(f"Data tallennettu välimuistiin: {cache_path}")
            except Exception as e:
                logging.error(f"Välimuistitiedoston {cache_path} tallennus epäonnistui: {e}")
            all_dfs.append(df_final)
        if not all_dfs:
            raise DataFetchError(f"Ei onnistuttu hakemaan dataa millekään kaudelle liigalle {league_code}.")
        return pd.concat(all_dfs, ignore_index=True)

class EloCalculator:
    def __init__(self, config: Config):
        self.config = config
        self.elo_ratings: Dict[str, float] = {}
        self.elo_history: Dict[str, List[Tuple[datetime, float]]] = {}
        self.elo_history_path: str = ""

    @staticmethod
    @jit(nopython=True)
    def _update_elo_numba(home_elo: float, away_elo: float, home_goals: int, away_goals: int, k_factor: float) -> Tuple[float, float]:
        expected_home = 1.0 / (1.0 + 10.0 ** ((away_elo - home_elo) / 400.0))
        if home_goals > away_goals:
            actual_home = 1.0
        elif home_goals == away_goals:
            actual_home = 0.5
        else:
            actual_home = 0.0
        new_home_elo = home_elo + k_factor * (actual_home - expected_home)
        new_away_elo = away_elo - k_factor * (actual_home - expected_home)
        return new_home_elo, new_away_elo

    def calculate_elo_ratings(self, df_finished: pd.DataFrame, league_code: str, season: int) -> Tuple[Dict[str, float], Dict[str, List[Tuple[datetime, float]]]]:
        if not {'homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals', 'utcDate'}.issubset(df_finished.columns):
            raise ValueError("DataFramesta puuttuu vaadittuja sarakkeita ELO-laskentaan.")
        df_sorted = df_finished.dropna(subset=['homeGoals', 'awayGoals']).copy()
        df_sorted['homeGoals'] = df_sorted['homeGoals'].astype(int)
        df_sorted['awayGoals'] = df_sorted['awayGoals'].astype(int)
        df_sorted = df_sorted.sort_values("utcDate")
        all_teams = pd.concat([df_sorted["homeTeamName"], df_sorted["awayTeamName"]]).unique()
        self.elo_ratings = {
            team: self.config.INITIAL_TOP_ELO if team in self.config.TOP_TEAMS else self.config.INITIAL_ELO
            for team in all_teams
        }
        self.elo_history = {team: [] for team in all_teams}
        self.elo_history_path = os.path.join(self.config.data_folder, f"elo_history_{league_code}_{season}.pkl")
        logging.info(f"Lasketaan ELO-pisteet {len(all_teams)} joukkueelle...")
        for _, row in tqdm(df_sorted.iterrows(), total=len(df_sorted), desc="Lasketaan ELO"):
            home_team, away_team = row["homeTeamName"], row["awayTeamName"]
            home_goals, away_goals = row["homeGoals"], row["awayGoals"]
            match_date = row["utcDate"]
            if home_team not in self.elo_ratings:
                self.elo_ratings[home_team] = self.config.INITIAL_ELO
                self.elo_history[home_team] = []
                logging.warning(f"Joukkue '{home_team}' ei löydy alustuksesta, lisätään oletus-ELO:lla.")
            if away_team not in self.elo_ratings:
                self.elo_ratings[away_team] = self.config.INITIAL_ELO
                self.elo_history[away_team] = []
                logging.warning(f"Joukkue '{away_team}' ei löydy alustuksesta, lisätään oletus-ELO:lla.")
            current_home_elo = self.elo_ratings[home_team]
            current_away_elo = self.elo_ratings[away_team]
            new_home_elo, new_away_elo = self._update_elo_numba(
                current_home_elo, current_away_elo, home_goals, away_goals, self.config.K_FACTOR
            )
            self.elo_ratings[home_team] = new_home_elo
            self.elo_ratings[away_team] = new_away_elo
            self.elo_history[home_team].append((match_date, new_home_elo))
            self.elo_history[away_team].append((match_date, new_away_elo))
        logging.info("ELO-laskenta valmis.")
        try:
            with open(self.elo_history_path, 'wb') as f:
                pickle.dump(self.elo_history, f)
            logging.info(f"ELO-historia tallennettu: {self.elo_history_path}")
        except Exception as e:
            logging.error(f"ELO-historian tallennus epäonnistui: {e}")
        return self.elo_ratings, self.elo_history

    def get_elo_for_match(self, home_team: str, away_team: str) -> Tuple[float, float]:
        home_elo = self.elo_ratings.get(home_team, self.config.INITIAL_ELO)
        away_elo = self.elo_ratings.get(away_team, self.config.INITIAL_ELO)
        return home_elo, away_elo

class FeaturePreprocessor:
    def __init__(self, config: Config):
        self.config = config
        self.scaler_path = os.path.join(config.model_folder, "scaler.pkl")
        self.imputer_path = os.path.join(config.model_folder, "imputer.pkl")
        self.feature_columns_path = os.path.join(config.model_folder, "feature_columns.json")
        self.scaler: Optional[StandardScaler] = None
        self.imputer: Optional[SimpleImputer] = None
        self.is_fitted: bool = False
        self.feature_columns_out: Optional[List[str]] = None
        self._load_preprocessors()

    def _load_preprocessors(self):
        try:
            if os.path.exists(self.scaler_path) and os.path.exists(self.imputer_path):
                self.scaler = joblib.load(self.scaler_path)
                self.imputer = joblib.load(self.imputer_path)
                if os.path.exists(self.feature_columns_path):
                    with open(self.feature_columns_path, 'r') as f:
                        self.feature_columns_out = json.load(f)
                self.is_fitted = True
                logging.info(f"Ladattiin esikäsittelijät hakemistosta {self.config.model_folder}")
            else:
                logging.info("Esikäsittelijätiedostoja ei löydy. Täytyy sovittaa.")
        except Exception as e:
            logging.error(f"Virhe ladattaessa esikäsittelijöitä: {e}. Täytyy sovittaa.")
            self.scaler = None
            self.imputer = None
            self.is_fitted = False
            self.feature_columns_out = None

    def _get_external_data(self, team: str, date: datetime, data_type: str) -> Any:
        logging.warning(f"Ulkoisia tietoja ({data_type}) ei ole implementoitu. Palautetaan oletusarvo.")
        key = f"{team}_{date.strftime('%Y-%m-%d')}"
        if data_type == "injury":
            return 0
        elif data_type == "xg":
            return {'xg_for': 1.5, 'xg_against': 1.5}
        elif data_type == "weather":
            return {'prob_rain': 0.0}
        return None

    def _calculate_vectorized_features(self, df: pd.DataFrame, df_history_for_context: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        if df.empty:
            return df
        logging.info("Lasketaan ominaisuudet vektorisoiduilla operaatioilla...")
        df_proc = df.copy()
        df_proc['utcDate'] = pd.to_datetime(df_proc['utcDate'], utc=True, errors='coerce')
        df_proc = df_proc.sort_values(by='utcDate').reset_index(drop=True)
        if df_history_for_context is None:
            logging.warning("Historiallista kontekstia ei annettu. Rullaavat ominaisuudet voivat olla epätarkkoja varhaisille otteluille.")
            df_context = pd.DataFrame()
        else:
            df_context = df_history_for_context.copy()
            df_context['utcDate'] = pd.to_datetime(df_context['utcDate'], utc=True, errors='coerce')
            min_prediction_date = df_proc['utcDate'].min()
            df_context = df_context[df_context['utcDate'] < min_prediction_date]
            df_context['homeGoals'] = pd.to_numeric(df_context.get('homeGoals'), errors='coerce')
            df_context['awayGoals'] = pd.to_numeric(df_context.get('awayGoals'), errors='coerce')
            df_context = df_context.dropna(subset=['homeGoals', 'awayGoals', 'homeTeamName', 'awayTeamName', 'utcDate'])
            df_context['homeGoals'] = df_context['homeGoals'].astype(int)
            df_context['awayGoals'] = df_context['awayGoals'].astype(int)
            df_context = df_context.sort_values(by='utcDate')
        df_combined = pd.concat([df_context, df_proc], ignore_index=True)
        df_combined = df_combined.sort_values(by='utcDate').reset_index(drop=True)
        id_vars = ['utcDate', 'homeGoals', 'awayGoals', 'homeTeamName', 'awayTeamName', 'season', 'league']
        df_combined = df_combined.reset_index()
        df_melt = pd.melt(df_combined,
                          id_vars=['index', 'utcDate', 'homeGoals', 'awayGoals', 'season', 'league'],
                          value_vars=['homeTeamName', 'awayTeamName'],
                          var_name='location', value_name='teamName')
        df_melt['location'] = df_melt['location'].str.replace('TeamName', '')
        df_melt = df_melt.sort_values(by=['teamName', 'utcDate', 'index'])
        df_melt['goal_diff'] = np.where(df_melt['location'] == 'home',
                                        df_melt['homeGoals'] - df_melt['awayGoals'],
                                        df_melt['awayGoals'] - df_melt['homeGoals'])
        df_melt['points'] = np.select(
            [df_melt['goal_diff'] > 0, df_melt['goal_diff'] == 0],
            [3, 1], default=0
        )
        df_melt[['goal_diff', 'points']] = df_melt[['goal_diff', 'points']].fillna(0)
        form_window = self.config.FEATURE_FORM_WINDOW
        df_melt[f'form_{form_window}'] = df_melt.groupby('teamName')['goal_diff'].transform(
            lambda x: x.shift(1).rolling(window=form_window, min_periods=1).mean()
        ).fillna(0.0)
        df_melt['cumulative_points'] = df_melt.groupby('teamName')['points'].transform(lambda x: x.shift(1).cumsum()).fillna(0)
        df_melt['games_played'] = df_melt.groupby('teamName').cumcount()
        df_melt['rank_pts_per_game'] = (df_melt['cumulative_points'] / df_melt['games_played'].replace(0, 1)).fillna(0.0)
        df_melt['ppg_location'] = df_melt.groupby(['teamName', 'location'])['points'].transform(
            lambda x: x.shift(1).rolling(window=999, min_periods=1).mean()
        ).fillna(0.0)
        df_melt['prev_match_date'] = df_melt.groupby('teamName')['utcDate'].shift(1)
        df_melt['rest_days'] = (df_melt['utcDate'] - df_melt['prev_match_date']).dt.days
        df_melt['rest_days'] = df_melt['rest_days'].fillna(7.0).clip(lower=0)
        features_to_pivot = [f'form_{form_window}', 'rank_pts_per_game', 'ppg_location', 'rest_days']
        df_pivoted = df_melt.pivot_table(index='index', columns='location', values=features_to_pivot)
        df_pivoted.columns = ['_'.join(col).strip() for col in df_pivoted.columns.values]
        rename_map = {
            f'form_{form_window}_home': 'form_home', f'form_{form_window}_away': 'form_away',
            'rank_pts_per_game_home': 'rank_pts_per_game_home', 'rank_pts_per_game_away': 'rank_pts_per_game_away',
            'ppg_location_home': 'ppg_home', 'ppg_location_away': 'ppg_away',
            'rest_days_home': 'rest_days_home', 'rest_days_away': 'rest_days_away'
        }
        df_pivoted = df_pivoted.rename(columns=rename_map)
        df_combined_featured = pd.merge(df_combined.drop(columns=['index']), df_pivoted, left_index=True, right_index=True, how='left')
        df_combined_featured = self._calculate_h2h_vectorized(df_combined_featured, df_combined, h2h_window=self.config.FEATURE_H2H_WINDOW)
        if 'elo_home' not in df_combined_featured.columns:
            df_combined_featured['elo_home'] = self.config.INITIAL_ELO
        if 'elo_away' not in df_combined_featured.columns:
            df_combined_featured['elo_away'] = self.config.INITIAL_ELO
        original_proc_indices = df_proc.index + len(df_context)
        df_final_featured = df_combined_featured.loc[original_proc_indices].reset_index(drop=True)
        logging.info("Ominaisuuslaskenta valmis.")
        return df_final_featured

    def _calculate_h2h_vectorized(self, df: pd.DataFrame, df_history: pd.DataFrame, h2h_window: int) -> pd.DataFrame:
        logging.info("Lasketaan H2H-ominaisuudet vektorisoidusti...")
        df_out = df.copy()
        df_out['h2h'] = 0.0
        df_history = df_history.copy()
        df_history['team_pair'] = df_history.apply(
            lambda row: '_'.join(sorted([row['homeTeamName'], row['awayTeamName']])),
            axis=1
        )
        df_out['team_pair'] = df_out.apply(
            lambda row: '_'.join(sorted([row['homeTeamName'], row['awayTeamName']])),
            axis=1
        )
        df_history['goal_diff'] = df_history['homeGoals'] - df_history['awayGoals']
        df_history['home_team_is_first'] = df_history['homeTeamName'] < df_history['awayTeamName']
        def compute_h2h(group):
            group = group.sort_values('utcDate')
            group['h2h'] = group['goal_diff'].shift(1).rolling(window=h2h_window, min_periods=1).mean().fillna(0.0)
            group['h2h'] = group.apply(
                lambda row: row['h2h'] if row['home_team_is_first'] else -row['h2h'],
                axis=1
            )
            return group[['utcDate', 'h2h']]
        try:
            h2h_data = df_history.groupby('team_pair').apply(compute_h2h, include_groups=False).reset_index()
        except Exception as e:
            logging.error(f"Virhe H2H-laskennassa: {e}. Palautetaan oletusarvo 0.")
            return df_out
        for idx, row in df_out.iterrows():
            match_date = row['utcDate']
            team_pair = row['team_pair']
            h2h_subset = h2h_data[(h2h_data['team_pair'] == team_pair) & (h2h_data['utcDate'] < match_date)]
            if not h2h_subset.empty:
                df_out.at[idx, 'h2h'] = h2h_subset['h2h'].iloc[-1]
        df_out = df_out.drop(columns=['team_pair'])
        logging.info("H2H-laskenta valmis.")
        return df_out

    def fit_transform(self, df_train: pd.DataFrame) -> pd.DataFrame:
        if self.is_fitted:
            logging.warning("Esikäsittelijä on jo sovitettu. Sovitetaan uudelleen.")
        df_featured = self._calculate_vectorized_features(df_train, df_history_for_context=df_train)
        self.imputer = SimpleImputer(strategy='constant', fill_value=0.0)
        self.scaler = StandardScaler()
        cols_to_process = [col for col in self.config.NUMERIC_FEATURES_TO_SCALE if col in df_featured.columns]
        missing_cols = [col for col in self.config.NUMERIC_FEATURES_TO_SCALE if col not in df_featured.columns]
        if missing_cols:
            logging.warning(f"Koulutusdatasta puuttuu skaalattavia sarakkeita: {missing_cols}. Ohitetaan sovituksessa.")
        if not cols_to_process:
            raise PreprocessingError("Ei numeerisia sarakkeita imputointiin/skaalaukseen.")
        df_featured[cols_to_process] = self.imputer.fit_transform(df_featured[cols_to_process])
        df_featured[cols_to_process] = self.scaler.fit_transform(df_featured[cols_to_process])
        logging.info(f"Imputoidut ja skaalatut sarakkeet: {cols_to_process}")
        clip_min, clip_max = self.config.FEATURE_CLIP_MIN, self.config.FEATURE_CLIP_MAX
        df_featured[cols_to_process] = df_featured[cols_to_process].clip(clip_min, clip_max)
        logging.info(f"Käytetty rajoitus ({clip_min}, {clip_max}) skaalatuille ominaisuuksille.")
        df_featured['elo_diff'] = df_featured['elo_home'] - df_featured['elo_away']
        df_featured['form_diff'] = df_featured['form_home'] - df_featured['form_away']
        df_featured['rank_diff'] = df_featured['rank_pts_per_game_home'] - df_featured['rank_pts_per_game_away']
        self.feature_columns_out = [col for col in self.config.MODEL_FEATURE_COLUMNS if col in df_featured.columns]
        missing_model_cols = [col for col in self.config.MODEL_FEATURE_COLUMNS if col not in df_featured.columns]
        if missing_model_cols:
            logging.warning(f"Koulutusdatasta puuttuu odotettuja mallin ominaisuuksia: {missing_model_cols}.")
        try:
            joblib.dump(self.scaler, self.scaler_path)
            joblib.dump(self.imputer, self.imputer_path)
            with open(self.feature_columns_path, 'w') as f:
                json.dump(self.feature_columns_out, f)
            self.is_fitted = True
            logging.info(f"Tallennettiin sovitetut esikäsittelijät hakemistoon {self.config.model_folder}")
        except Exception as e:
            logging.error(f"Esikäsittelijöiden tallennus epäonnistui: {e}")
            raise PreprocessingError(f"Esikäsittelijöiden tallennus epäonnistui: {e}") from e
        return df_featured[self.feature_columns_out]

    def transform(self, df: pd.DataFrame, df_ref: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        if not self.is_fitted:
            raise PreprocessingError("Esikäsittelijää ei ole sovitettu.")
        if self.feature_columns_out is None:
            raise PreprocessingError("Esikäsittelijä on sovitettu, mutta ominaisuusjärjestys puuttuu. Sovita uudelleen.")
        df_featured = self._calculate_vectorized_features(df, df_history_for_context=df_ref)
        cols_to_process = [col for col in self.config.NUMERIC_FEATURES_TO_SCALE if col in df_featured.columns]
        missing_cols = [col for col in self.config.NUMERIC_FEATURES_TO_SCALE if col not in df_featured.columns]
        if missing_cols:
            logging.warning(f"Ennustedatasta puuttuu skaalattavia sarakkeita: {missing_cols}. Lisätään oletusarvo 0.")
            for col in missing_cols:
                df_featured[col] = 0.0
            cols_to_process.extend([col for col in missing_cols if col in self.config.NUMERIC_FEATURES_TO_SCALE])
            cols_to_process = list(dict.fromkeys(cols_to_process))
        if not cols_to_process:
            logging.warning("Ei numeerisia sarakkeita muunnokseen.")
            df_featured['elo_diff'] = df_featured.get('elo_home', 0.0) - df_featured.get('elo_away', 0.0)
            df_featured['form_diff'] = df_featured.get('form_home', 0.0) - df_featured.get('form_away', 0.0)
            df_featured['rank_diff'] = df_featured.get('rank_pts_per_game_home', 0.0) - df_featured.get('rank_pts_per_game_away', 0.0)
        else:
            try:
                cols_present_at_fit = [col for col in cols_to_process if col in self.scaler.feature_names_in_]
                if len(cols_present_at_fit) != len(cols_to_process):
                    logging.warning(f"Ero prosessoitavien sarakkeiden ja sovituksessa nähtyjen välillä. Käsitellään vain {cols_present_at_fit}")
                df_featured[cols_present_at_fit] = self.imputer.transform(df_featured[cols_present_at_fit])
                df_featured[cols_present_at_fit] = self.scaler.transform(df_featured[cols_present_at_fit])
            except ValueError as e:
                logging.error(f"Muunnosvirhe (todennäköisesti muoto- tai sarakeongelma): {e}")
                raise PreprocessingError(f"Muunnosvirhe: {e}") from e
            except Exception as e:
                logging.error(f"Odottamaton muunnosvirhe: {e}", exc_info=True)
                raise PreprocessingError(f"Odottamaton muunnosvirhe: {e}") from e
            clip_min, clip_max = self.config.FEATURE_CLIP_MIN, self.config.FEATURE_CLIP_MAX
            df_featured[cols_present_at_fit] = df_featured[cols_present_at_fit].clip(clip_min, clip_max)
            df_featured['elo_diff'] = df_featured['elo_home'] - df_featured['elo_away']
            df_featured['form_diff'] = df_featured['form_home'] - df_featured['form_away']
            df_featured['rank_diff'] = df_featured['rank_pts_per_game_home'] - df_featured['rank_pts_per_game_away']
        final_df = pd.DataFrame(columns=self.feature_columns_out, index=df_featured.index)
        for col in self.feature_columns_out:
            if col in df_featured.columns:
                final_df[col] = df_featured[col]
            else:
                logging.warning(f"Ennustedatasta puuttuu odotettu ominaisuus '{col}'. Lisätään oletusarvo 0.")
                final_df[col] = 0.0
        return final_df[self.feature_columns_out]

class BayesianPredictor:
    def __init__(self, config: Config):
        self.config = config
        self.trace: Optional[az.InferenceData] = None
        self.teams: List[str] = []
        self.team_idx_map: Dict[str, int] = {}
        self.model_feature_columns_used: Optional[List[str]] = None
        self.trace_path_template = os.path.join(config.model_folder, "bayesian_trace_{timestamp}.nc")

    def fit(self, df_train: pd.DataFrame, teams: List[str]):
        logging.info("Sovitetaan Bayesilainen malli...")
        start_time = time.time()
        # Päivitä joukkueet vain koulutukseen osallistuvilla joukkueilla
        actual_teams = pd.concat([df_train["homeTeamName"], df_train["awayTeamName"]]).unique().tolist()
        self.teams = actual_teams
        self.team_idx_map = {name: i for i, name in enumerate(self.teams)}
        self.model_feature_columns_used = [col for col in df_train.columns if col not in ['homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals']]
        df_fit = df_train.copy()
        if not {'homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals'}.issubset(df_fit.columns):
            raise ModelError("Koulutusdatasta puuttuu joukkuenimet tai maalit.")
        df_fit["home_idx"] = df_fit["homeTeamName"].map(self.team_idx_map)
        df_fit["away_idx"] = df_fit["awayTeamName"].map(self.team_idx_map)
        df_fit = df_fit.dropna(subset=['home_idx', 'away_idx', 'homeGoals', 'awayGoals'] + self.model_feature_columns_used)
        if df_fit.empty:
            raise ModelError("Ei validia dataa Bayesilaisen mallin sovittamiseen.")
        home_idx = df_fit["home_idx"].values.astype(int)
        away_idx = df_fit["away_idx"].values.astype(int)
        observed_home_goals = df_fit["homeGoals"].values.astype(int)
        observed_away_goals = df_fit["awayGoals"].values.astype(int)
        n_teams = len(self.teams)
        n_matches = len(df_fit)
        coords = {"team": self.teams, "match": df_fit.index}
        with pm.Model(coords=coords) as model:
            intercept = pm.Normal("intercept", mu=np.log(df_fit[['homeGoals', 'awayGoals']].mean().mean() + 1e-6), sigma=0.5)
            attack_offset = pm.Normal("attack_offset", mu=0, sigma=0.5, dims="team")
            attack_sigma = pm.HalfNormal("attack_sigma", sigma=0.5)
            attack = pm.Deterministic("attack", intercept + attack_offset * attack_sigma, dims="team")
            defense_offset = pm.Normal("defense_offset", mu=0, sigma=0.5, dims="team")
            defense_sigma = pm.HalfNormal("defense_sigma", sigma=0.5)
            defense = pm.Deterministic("defense", defense_offset * defense_sigma, dims="team")
            home_adv_offset = pm.Normal("home_adv_offset", mu=0, sigma=0.5, dims="team")
            home_adv_sigma = pm.HalfNormal("home_adv_sigma", sigma=0.2)
            home_advantage = pm.Deterministic("home_advantage", home_adv_offset * home_adv_sigma, dims="team")
            feature_effects = {}
            for feature in self.model_feature_columns_used:
                feature_effects[feature] = pm.Normal(f"beta_{feature}", mu=0, sigma=0.2)
            log_theta_home = attack[home_idx] - defense[away_idx] + home_advantage[home_idx]
            log_theta_away = attack[away_idx] - defense[home_idx]
            for feature, beta in feature_effects.items():
                feature_values = df_fit[feature].values
                if feature.endswith("_home"):
                    log_theta_home += beta * feature_values
                elif feature.endswith("_away"):
                    log_theta_away += beta * feature_values
                elif feature.endswith("_diff") or feature == "h2h":
                    log_theta_home += beta * feature_values
                    log_theta_away -= beta * feature_values
            if self.config.USE_NEGBIN:
                alpha = pm.HalfNormal('alpha', sigma=1)
                pm.NegativeBinomial("home_goals", mu=pm.math.exp(log_theta_home), alpha=alpha,
                                    observed=observed_home_goals, dims="match")
                pm.NegativeBinomial("away_goals", mu=pm.math.exp(log_theta_away), alpha=alpha,
                                    observed=observed_away_goals, dims="match")
            else:
                pm.Poisson("home_goals", mu=pm.math.exp(log_theta_home),
                           observed=observed_home_goals, dims="match")
                pm.Poisson("away_goals", mu=pm.math.exp(log_theta_away),
                           observed=observed_away_goals, dims="match")
            sampling_params = self.config.SAMPLING_PARAMS[self.config.SAMPLING_MODE]
            logging.info(f"Aloitetaan PyMC-näytteenotto moodilla '{self.config.SAMPLING_MODE}': {sampling_params}")
            self.trace = pm.sample(
                draws=sampling_params["draws"],
                tune=sampling_params["tune"],
                chains=sampling_params["chains"],
                target_accept=0.90,
                progressbar=True,
                random_seed=42,
                return_inferencedata=True,
                idata_kwargs={"log_likelihood": True}
            )
            with model:
                posterior_predictive = pm.sample_posterior_predictive(self.trace, random_seed=42)
                self.trace = self.trace.extend(posterior_predictive)
            duration = time.time() - start_time
            logging.info(f"Bayesilaisen mallin sovitus valmis {duration:.2f} sekunnissa.")
            try:
                summary = az.summary(self.trace, round_to=3)
                logging.info("ArviZ-yhteenveto:\n" + summary.to_string())
                divergences = self.trace.sample_stats.diverging.sum().item()
                if divergences > 0:
                    logging.warning(f"NUTS-näytteenottaja kohtasi {divergences} divergenssiä.")
                min_ess_bulk = summary['ess_bulk'].min()
                min_ess_tail = summary['ess_tail'].min()
                max_rhat = summary['r_hat'].max()
                logging.info(f"Min ESS Bulk: {min_ess_bulk:.1f}, Min ESS Tail: {min_ess_tail:.1f}, Max R-hat: {max_rhat:.3f}")
                if min_ess_bulk < 400 or min_ess_tail < 400 or max_rhat > 1.01:
                    logging.warning("Mahdollisia konvergenssiongelmia havaittu (matala ESS tai korkea R-hat).")
            except Exception as e:
                logging.error(f"Virhe ArviZ-yhteenvedon luomisessa: {e}")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            trace_path = self.trace_path_template.format(timestamp=timestamp)
            try:
                self.trace.to_netcdf(trace_path)
                logging.info(f"Bayesilaisen mallin jälki tallennettu: {trace_path}")
            except Exception as e:
                logging.error(f"Jäljen tallennus epäonnistui: {e}")

    def predict(self, df_predict: pd.DataFrame) -> List[Dict[str, Any]]:
        if self.trace is None:
            raise ModelError("Bayesilaista mallia ei ole sovitettu.")
        if self.model_feature_columns_used is None:
            raise ModelError("Sovitettuja ominaisuussarakkeita ei tiedetä.")
        if df_predict.empty:
            return []
        logging.info(f"Generoidaan Bayesilaisia ennusteita {len(df_predict)} ottelulle...")
        predictions = []
        missing_features = [f for f in self.model_feature_columns_used if f not in df_predict.columns]
        if missing_features:
            raise ModelError(f"Ennustedatasta puuttuu sovituksessa käytettyjä ominaisuuksia: {missing_features}")
        home_indices = df_predict["homeTeamName"].map(self.team_idx_map)
        away_indices = df_predict["awayTeamName"].map(self.team_idx_map)
        unknown_teams = df_predict[home_indices.isna() | away_indices.isna()][['homeTeamName', 'awayTeamName']]
        if not unknown_teams.empty:
            logging.warning(f"Tuntemattomia joukkueita ennusteissa: {unknown_teams.values.tolist()}")
            home_indices = home_indices.fillna(-1).astype(int)
            away_indices = away_indices.fillna(-1).astype(int)
        n_samples_total = self.trace.posterior.dims["chain"] * self.trace.posterior.dims["draw"]
        try:
            posterior = self.trace.posterior.stack(sample=("chain", "draw"))
        except Exception as e:
            raise ModelError(f"Posterior-näytteiden pinoaminen epäonnistui: {e}") from e
        try:
            intercept = posterior["intercept"].values
            attack = posterior["attack"].values
            defense = posterior["defense"].values
            home_advantage = posterior["home_advantage"].values
            feature_effects = {feat: posterior[f"beta_{feat}"].values
                               for feat in self.model_feature_columns_used if f"beta_{feat}" in posterior}
            alpha = posterior["alpha"].values if self.config.USE_NEGBIN else None
        except KeyError as e:
            raise ModelError(f"Posterior-jäljestä puuttuu parametri: {e}.") from e
        for i, row in tqdm(df_predict.iterrows(), total=len(df_predict), desc="Bayesilaiset ennusteet"):
            home_idx = int(home_indices[i])
            away_idx = int(away_indices[i])
            if home_idx == -1 or away_idx == -1 or home_idx >= attack.shape[1] or away_idx >= attack.shape[1]:
                logging.warning(f"Ohitetaan Bayes-ennuste ottelulle {row['homeTeamName']} vs {row['awayTeamName']} tuntemattoman joukkueen tai virheellisen indeksin vuoksi.")
                predictions.append({
                    "homeTeamName": row['homeTeamName'],
                    "awayTeamName": row['awayTeamName'],
                    "model_type": "Bayesian (Skipped - Invalid Index)"
                })
                continue
            match_features = row[self.model_feature_columns_used].to_dict()
            log_mu_home_s = intercept + attack[:, home_idx] - defense[:, away_idx] + home_advantage[:, home_idx]
            log_mu_away_s = intercept + attack[:, away_idx] - defense[:, home_idx]
            for feature, beta in feature_effects.items():
                if feature in match_features:
                    feature_value = match_features[feature]
                    if feature.endswith("_home"):
                        log_mu_home_s += beta * feature_value
                    elif feature.endswith("_away"):
                        log_mu_away_s += beta * feature_value
                    elif feature.endswith("_diff") or feature == "h2h":
                        log_mu_home_s += beta * feature_value
                        log_mu_away_s -= beta * feature_value
            mu_home_s = np.exp(log_mu_home_s)
            mu_away_s = np.exp(log_mu_away_s)
            if self.config.USE_NEGBIN:
                n_h = alpha
                p_h = alpha / (alpha + mu_home_s + 1e-9)
                n_a = alpha
                p_a = alpha / (alpha + mu_away_s + 1e-9)
                pred_home = nbinom.rvs(n=n_h, p=p_h, size=n_samples_total)
                pred_away = nbinom.rvs(n=n_a, p=p_a, size=n_samples_total)
            else:
                pred_home = poisson.rvs(mu=mu_home_s, size=n_samples_total)
                pred_away = poisson.rvs(mu=mu_away_s, size=n_samples_total)
            wins_home = np.sum(pred_home > pred_away)
            wins_away = np.sum(pred_home < pred_away)
            draws = n_samples_total - wins_home - wins_away
            probs_1x2 = [wins_away / n_samples_total, draws / n_samples_total, wins_home / n_samples_total]
            total_goals = pred_home + pred_away
            prob_over_2_5 = float(np.mean(total_goals > 2.5))
            prob_btts = float(np.mean((pred_home > 0) & (pred_away > 0)))
            score_counts = Counter(f"{int(h)}-{int(a)}" for h, a in zip(pred_home, pred_away))
            correct_scores = {k: v / n_samples_total for k, v in score_counts.items()}
            top_scores = dict(sorted(correct_scores.items(), key=lambda item: item[1], reverse=True)[:5])
            predictions.append({
                "homeTeamName": row['homeTeamName'], "awayTeamName": row['awayTeamName'],
                "mu_home": float(np.mean(mu_home_s)),
                "mu_away": float(np.mean(mu_away_s)),
                "probs_1x2": probs_1x2,
                "prob_over_2_5": prob_over_2_5,
                "prob_btts": prob_btts,
                "top_correct_scores": top_scores,
                "model_type": "Bayesian",
                "mu_home_samples": mu_home_s,
                "mu_away_samples": mu_away_s
            })
        logging.info("Bayesilaisten ennusteiden generointi valmis.")
        return predictions

class NeuralNetworkPredictor:
    def __init__(self, config: Config):
        self.config = config
        self.model: Optional[tf.keras.Model] = None
        self.model_path = os.path.join(config.model_folder, "nn_model.keras")
        self.input_dim: Optional[int] = None

    def build_model(self, input_dim: int):
        self.input_dim = input_dim
        model = Sequential([
            tf.keras.layers.Input(shape=(input_dim,)),
            Dense(128, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            Dense(64, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            Dense(32, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            Dense(2, activation='softplus')
        ])
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                      loss=tf.keras.losses.Poisson(),
                      metrics=['mae'])
        logging.info("Neuroverkkomalli rakennettu.")
        model.summary(print_fn=logging.info)
        self.model = model

    def train(self, X_train: np.ndarray, y_train: np.ndarray):
        if self.model is None:
            self.build_model(X_train.shape[1])
        elif self.input_dim != X_train.shape[1]:
            logging.warning(f"Syötteen dimensio ei täsmää. Odotettu {self.input_dim}, saatu {X_train.shape[1]}. Rakennetaan malli uudelleen.")
            self.build_model(X_train.shape[1])
        if self.model is None:
            raise ModelError("NN-mallin rakentaminen epäonnistui ennen koulutusta.")
        logging.info(f"Aloitetaan NN-koulutus {X_train.shape[0]} näytteellä...")
        start_time = time.time()
        if y_train.ndim == 1 or y_train.shape[1] != 2:
            raise ValueError(f"y_train odotetaan muotoa (n_samples, 2), saatiin {y_train.shape}")
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=self.config.NN_EARLY_STOPPING_PATIENCE,
                          restore_best_weights=True, verbose=1)
        ]
        history = self.model.fit(
            X_train, y_train,
            epochs=self.config.NN_EPOCHS,
            batch_size=self.config.NN_BATCH_SIZE,
            validation_split=self.config.NN_VALIDATION_SPLIT,
            callbacks=callbacks,
            verbose=1
        )
        duration = time.time() - start_time
        logging.info(f"NN-koulutus valmis {duration:.2f} sekunnissa.")
        try:
            self.model.save(self.model_path)
            logging.info(f"NN-malli tallennettu: {self.model_path}")
        except Exception as e:
            logging.error(f"NN-mallin tallennus epäonnistui: {e}")
        return history

    def load_model(self) -> bool:
        if os.path.exists(self.model_path):
            try:
                self.model = load_model(self.model_path)
                logging.info(f"Ladattiin NN-malli: {self.model_path}")
                self.input_dim = self.model.input_shape[1]
                return True
            except Exception as e:
                logging.error(f"NN-mallin lataus epäonnistui: {e}")
                self.model = None
                return False
        else:
            logging.warning(f"NN-mallitiedostoa ei löydy: {self.model_path}")
            self.model = None
            return False

    def predict_with_uncertainty(self, X_predict: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        if self.model is None:
            if not self.load_model():
                raise ModelError("NN-mallia ei ole saatavilla ennustamiseen.")
        if self.model.input_shape[1] is not None and X_predict.shape[1] != self.model.input_shape[1]:
            raise ValueError(f"Syötedatassa {X_predict.shape[1]} ominaisuutta, NN-malli odottaa {self.model.input_shape[1]}.")
        if X_predict.ndim == 1:
            X_predict = X_predict.reshape(1, -1)
        logging.info(f"Generoidaan NN-ennusteet MC Dropoutilla ({self.config.MC_DROPOUT_SAMPLES} näytettä)...")
        try:
            predictions_mc = []
            dropout_model = tf.keras.Model(inputs=self.model.inputs, outputs=self.model.outputs)
            for _ in tqdm(range(self.config.MC_DROPOUT_SAMPLES), desc="MC Dropout", leave=False):
                preds = dropout_model(X_predict, training=True)
                predictions_mc.append(preds.numpy())
            predictions_mc = np.stack(predictions_mc)
            mean_preds = np.mean(predictions_mc, axis=0)
            std_preds = np.std(predictions_mc, axis=0)
            return mean_preds, std_preds, predictions_mc
        except Exception as e:
            logging.error(f"Virhe MC Dropout -ennustuksessa: {e}", exc_info=True)
            try:
                logging.warning("Palataan tavalliseen NN-ennusteeseen ilman epävarmuutta.")
                mean_preds = self.model.predict(X_predict)
                return mean_preds, np.zeros_like(mean_preds), np.array([mean_preds])
            except Exception as e_inner:
                logging.error(f"Tavallinen NN-ennustus epäonnistui: {e_inner}")
                raise ModelError("NN-ennustus epäonnistui, myös varamalli.") from e_inner

class MatchPredictor:
    """Orkestroi ennusteet Bayes-, NN- tai varamalleilla."""

    def __init__(self, config: Config, bayesian_predictor: BayesianPredictor,
                 nn_predictor: NeuralNetworkPredictor, elo_calculator: EloCalculator):
        self.config = config
        self.bayesian_predictor = bayesian_predictor
        self.nn_predictor = nn_predictor
        self.elo_calculator = elo_calculator

    def _predict_fallback(self, home_team: str, away_team: str) -> Dict[str, Any]:
        """Generoi yksinkertaisen varamalli-ennusteen ELO-pohjalta."""
        home_elo, away_elo = self.elo_calculator.get_elo_for_match(home_team, away_team)
        elo_diff = home_elo - away_elo

        prob_home_win_elo = 1.0 / (1.0 + 10.0 ** (-elo_diff / 400.0))
        prob_away_win_elo = 1.0 - prob_home_win_elo

        prob_draw = 0.25  # Yksinkertainen tasapeliarvio
        prob_home = prob_home_win_elo * (1.0 - prob_draw)
        prob_away = prob_away_win_elo * (1.0 - prob_draw)

        total = prob_home + prob_away + prob_draw
        if total < 1e-9:
            total = 1.0
        probs_1x2 = [prob_away / total, prob_draw / total, prob_home / total]

        avg_goals = 2.5  # Karkea keskiarvo
        mu_home = max(probs_1x2[2] * avg_goals + probs_1x2[1] * avg_goals / 2, 0.1)
        mu_away = max(probs_1x2[0] * avg_goals + probs_1x2[1] * avg_goals / 2, 0.1)

        probs_1x2, prob_over_2_5, prob_btts, top_scores = self.compute_probabilities(mu_home, mu_away)

        return {
            "homeTeamName": home_team, "awayTeamName": away_team,
            "mu_home": mu_home, "mu_away": mu_away, "probs_1x2": probs_1x2,
            "prob_over_2_5": prob_over_2_5, "prob_btts": prob_btts,
            "top_correct_scores": top_scores, "model_type": "Fallback (ELO)"
        }

    @staticmethod
    def compute_probabilities(mu_home: Any, mu_away: Any, max_goals: int = 10, samples: Optional[np.ndarray] = None) -> Tuple[List[float], float, float, Dict[str, float]]:
        """Laskee todennäköisyydet odotetuista maaleista, huomioiden epävarmuuden."""
        if samples is not None:  # Bayes- tai NN-näytteet
            mu_home_s = samples[:, :, 0] if samples.ndim == 3 else samples[:, 0]
            mu_away_s = samples[:, :, 1] if samples.ndim == 3 else samples[:, 1]
            n_samples = mu_home_s.shape[0]
            probs_1x2 = np.zeros((mu_home_s.shape[1], 3)) if mu_home_s.ndim > 1 else np.zeros(3)
            prob_over_2_5 = np.zeros(mu_home_s.shape[1]) if mu_home_s.ndim > 1 else 0.0
            prob_btts = np.zeros(mu_home_s.shape[1]) if mu_home_s.ndim > 1 else 0.0
            score_probs = [Counter() for _ in range(mu_home_s.shape[1])] if mu_home_s.ndim > 1 else Counter()

            for i in range(mu_home_s.shape[1] if mu_home_s.ndim > 1 else 1):
                for s in range(n_samples):
                    mu_h = max(mu_home_s[s, i] if mu_home_s.ndim > 1 else mu_home_s[s], 0.01)
                    mu_a = max(mu_away_s[s, i] if mu_away_s.ndim > 1 else mu_away_s[s], 0.01)
                    pmf_h = poisson.pmf(range(max_goals + 1), mu_h)
                    pmf_a = poisson.pmf(range(max_goals + 1), mu_a)
                    for h in range(max_goals + 1):
                        for a in range(max_goals + 1):
                            prob = pmf_h[h] * pmf_a[a]
                            score_probs[i][f"{h}-{a}"] += prob / n_samples
                            if h > a:
                                probs_1x2[i, 2] += prob / n_samples
                            elif h == a:
                                probs_1x2[i, 1] += prob / n_samples
                            else:
                                probs_1x2[i, 0] += prob / n_samples
                            if h + a >= 3:
                                prob_over_2_5[i] += prob / n_samples
                            if h > 0 and a > 0:
                                prob_btts[i] += prob / n_samples
                top_scores = dict(sorted(score_probs[i].items(), key=lambda item: item[1], reverse=True)[:5])
                if mu_home_s.ndim == 1:
                    return probs_1x2.tolist(), prob_over_2_5, prob_btts, top_scores
            return [p.tolist() for p in probs_1x2], prob_over_2_5.tolist(), prob_btts.tolist(), top_scores

        # Piste-estimaatti (varamalli)
        mu_home = max(float(mu_home), 0.01)
        mu_away = max(float(mu_away), 0.01)
        prob_home_win, prob_draw, prob_away_win = 0.0, 0.0, 0.0
        score_probs = Counter()

        pmf_home = poisson.pmf(range(max_goals + 1), mu_home)
        pmf_away = poisson.pmf(range(max_goals + 1), mu_away)

        for h in range(max_goals + 1):
            for a in range(max_goals + 1):
                prob = pmf_home[h] * pmf_away[a]
                score_probs[f"{h}-{a}"] += prob
                if h > a:
                    prob_home_win += prob
                elif h == a:
                    prob_draw += prob
                else:
                    prob_away_win += prob

        total_prob_1x2 = prob_home_win + prob_draw + prob_away_win
        probs_1x2 = [prob_away_win / total_prob_1x2, prob_draw / total_prob_1x2, prob_home_win / total_prob_1x2] if total_prob_1x2 > 1e-9 else [1/3, 1/3, 1/3]
        prob_over_2_5 = sum(score_probs[f"{h}-{a}"] for h in range(max_goals + 1) for a in range(max_goals + 1) if h + a >= 3)
        prob_btts = sum(score_probs[f"{h}-{a}"] for h in range(1, max_goals + 1) for a in range(1, max_goals + 1))
        top_scores = dict(sorted(score_probs.items(), key=lambda item: item[1], reverse=True)[:5])

        return probs_1x2, prob_over_2_5, prob_btts, top_scores

    def predict_matches(self, df_predict: pd.DataFrame, X_predict_processed: pd.DataFrame) -> List[Dict[str, Any]]:
        if df_predict.index.tolist() != X_predict_processed.index.tolist():
            logging.warning("Indeksit eivät täsmää ennuste- ja prosessoidun datan välillä. Kohdistetaan uudelleen.")
            X_predict_processed = X_predict_processed.reindex(df_predict.index)
            if X_predict_processed.index.tolist() != df_predict.index.tolist():
                raise ValueError("Indeksien kohdistus epäonnistui.")
        all_predictions = []
        nn_preds_mean = None
        nn_preds_std = None
        nn_samples = None
        nn_prediction_successful = False
        if self.config.USE_NN:
            try:
                nn_preds_mean, nn_preds_std, nn_samples = self.nn_predictor.predict_with_uncertainty(X_predict_processed.values)
                nn_prediction_successful = True
                logging.info("NN-ennusteet generoitu onnistuneesti.")
            except ModelError as e:
                logging.warning(f"NN-ennustus epäonnistui: {e}. Yritetään Bayes- tai varamallia.")
            except Exception as e:
                logging.error(f"Odottamaton virhe NN-ennustuksessa: {e}", exc_info=True)
        bayesian_preds = None
        bayesian_prediction_successful = False
        should_try_bayesian = (not self.config.USE_NN) or (not nn_prediction_successful) or (self.bayesian_predictor.trace is not None)
        if should_try_bayesian and self.bayesian_predictor.trace is not None:
            try:
                df_predict_with_features = pd.concat([df_predict[['homeTeamName', 'awayTeamName']], X_predict_processed], axis=1)
                bayesian_preds_list = self.bayesian_predictor.predict(df_predict_with_features)
                bayesian_preds = {(p['homeTeamName'], p['awayTeamName']): p for p in bayesian_preds_list if p.get('model_type') != "Bayesian (Skipped - Invalid Index)"}
                bayesian_prediction_successful = True
                logging.info("Bayesilaiset ennusteet generoitu onnistuneesti.")
            except ModelError as e:
                logging.warning(f"Bayes-ennustus epäonnistui: {e}. Käytetään varamallia, jos NN epäonnistui.")
            except Exception as e:
                logging.error(f"Odottamaton virhe Bayes-ennustuksessa: {e}", exc_info=True)
        for i, row in df_predict.iterrows():
            home_team = row['homeTeamName']
            away_team = row['awayTeamName']
            final_pred = None
            if self.config.USE_NN and nn_prediction_successful:
                if i >= len(nn_preds_mean):
                    logging.error(f"NN-ennusteen indeksi {i} ylittää ennusteiden määrän {len(nn_preds_mean)}. Käytetään varamallia.")
                    final_pred = self._predict_fallback(home_team, away_team)
                else:
                    mu_home_nn, mu_away_nn = nn_preds_mean[i]
                    probs_1x2, prob_over_2_5, prob_btts, top_scores = self.compute_probabilities(
                        mu_home_nn, mu_away_nn, samples=nn_samples[:, i:i+1, :]
                    )
                    final_pred = {
                        "homeTeamName": home_team, "awayTeamName": away_team,
                        "mu_home": float(mu_home_nn), "mu_away": float(mu_away_nn),
                        "mu_home_std": float(nn_preds_std[i, 0]), "mu_away_std": float(nn_preds_std[i, 1]),
                        "probs_1x2": probs_1x2, "prob_over_2_5": prob_over_2_5,
                        "prob_btts": prob_btts, "top_correct_scores": top_scores,
                        "model_type": "Neural Network"
                    }
            elif bayesian_preds is not None and (home_team, away_team) in bayesian_preds:
                bayes_pred = bayesian_preds[(home_team, away_team)]
                mu_home_s = bayes_pred.get("mu_home_samples")
                mu_away_s = bayes_pred.get("mu_away_samples")
                if mu_home_s is not None and mu_away_s is not None:
                    samples = np.stack([mu_home_s, mu_away_s], axis=-1)
                    probs_1x2, prob_over_2_5, prob_btts, top_scores = self.compute_probabilities(
                        bayes_pred["mu_home"], bayes_pred["mu_away"], samples=samples
                    )
                    bayes_pred["probs_1x2"] = probs_1x2
                    bayes_pred["prob_over_2_5"] = prob_over_2_5
                    bayes_pred["prob_btts"] = prob_btts
                    bayes_pred["top_correct_scores"] = top_scores
                final_pred = bayes_pred
            else:
                logging.warning(f"Käytetään varamallin ennustetta ottelulle {home_team} vs {away_team}.")
                final_pred = self._predict_fallback(home_team, away_team)
            all_predictions.append(final_pred)
        return all_predictions

# --- Arviointimoduuli ---
class Evaluator:
    """Käsittelee mallien arviointia jälkitestauksella ja visualisoinneilla."""

    def __init__(self, config: Config, predictor: MatchPredictor, preprocessor: FeaturePreprocessor):
        self.config = config
        self.predictor = predictor
        self.preprocessor = preprocessor
        self.results_history: List[Dict[str, Any]] = []

    def run_backtest(self, df_all_matches: pd.DataFrame, elo_calculator: EloCalculator,
                     bayesian_trainer: BayesianPredictor, nn_trainer: NeuralNetworkPredictor) -> pd.DataFrame:
        """Suorittaa walk-forward-jälkitestauksen."""
        logging.info("Aloitetaan walk-forward-jälkitestaus...")
        self.results_history = []

        df_finished = df_all_matches[df_all_matches['status'] == 'FINISHED'].copy()
        df_finished = df_finished.sort_values('utcDate').reset_index(drop=True)

        if len(df_finished) < 50:
            logging.warning("Riittämätön historiallinen data jälkitestaukseen.")
            return pd.DataFrame()

        initial_train_size = int(len(df_finished) * self.config.BACKTEST_TRAIN_SPLIT_RATIO)
        retrain_step = self.config.BACKTEST_RETRAIN_STEP

        logging.info(f"Alustava koulutus ensimmäisillä {initial_train_size} otteluilla.")
        df_initial_train = df_finished.iloc[:initial_train_size]

        current_elo_ratings, _ = elo_calculator.calculate_elo_ratings(df_initial_train, self.config.DEFAULT_LEAGUE_CODE, get_current_season())
        df_initial_train['elo_home'] = df_initial_train['homeTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)
        df_initial_train['elo_away'] = df_initial_train['awayTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)

        try:
            X_initial_train_processed = self.preprocessor.fit_transform(df_initial_train)
            X_initial_train_processed = pd.concat([df_initial_train[['homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals']], X_initial_train_processed], axis=1)
            y_initial_train = df_initial_train[['homeGoals', 'awayGoals']].values
        except (PreprocessingError, ValueError) as e:
            logging.error(f"Virhe alustavassa esikäsittelyn sovituksessa/muunnoksessa: {e}", exc_info=True)
            return pd.DataFrame()

        try:
            all_teams = pd.concat([df_finished["homeTeamName"], df_finished["awayTeamName"]]).unique().tolist()
            bayesian_trainer.fit(X_initial_train_processed, all_teams)
        except ModelError as e:
            logging.error(f"Alustava Bayes-mallin koulutus epäonnistui: {e}")
        except Exception as e:
            logging.error(f"Odottamaton virhe alustavassa Bayes-koulutuksessa: {e}", exc_info=True)

        if self.config.USE_NN:
            try:
                nn_feature_cols = [f for f in self.preprocessor.feature_columns_out if f in X_initial_train_processed.columns]
                nn_trainer.train(X_initial_train_processed[nn_feature_cols].values, y_initial_train)
            except ModelError as e:
                logging.error(f"Alustava NN-mallin koulutus epäonnistui: {e}")
            except Exception as e:
                logging.error(f"Odottamaton virhe alustavassa NN-koulutuksessa: {e}", exc_info=True)

        for i in tqdm(range(initial_train_size, len(df_finished)), desc="Jälkitestaus"):
            current_match = df_finished.iloc[[i]].copy()
            df_history_context = df_finished.iloc[:i]

            if (i - initial_train_size) % retrain_step == 0 and i > initial_train_size:
                logging.info(f"Uudelleenkoulutetaan malleja askeleella {i} (käytetään {i} ottelua)...")
                current_elo_ratings, _ = elo_calculator.calculate_elo_ratings(df_history_context, self.config.DEFAULT_LEAGUE_CODE, get_current_season())
                df_history_context_with_elo = df_history_context.copy()
                df_history_context_with_elo['elo_home'] = df_history_context_with_elo['homeTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)
                df_history_context_with_elo['elo_away'] = df_history_context_with_elo['awayTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)

                try:
                    X_train_processed = self.preprocessor.fit_transform(df_history_context_with_elo)
                    X_train_processed = pd.concat([df_history_context_with_elo[['homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals']], X_train_processed], axis=1)
                    y_train = df_history_context_with_elo[['homeGoals', 'awayGoals']].values
                except (PreprocessingError, ValueError) as e:
                    logging.error(f"Virhe uudelleenkoulutuksen esikäsittelyn sovituksessa/muunnoksessa askeleella {i}: {e}", exc_info=True)
                    continue

                try:
                    bayesian_trainer.fit(X_train_processed, all_teams)
                except ModelError as e:
                    logging.error(f"Bayes-uudelleenkoulutus epäonnistui askeleella {i}: {e}")
                except Exception as e:
                    logging.error(f"Odottamaton virhe Bayes-uudelleenkoulutuksessa: {e}", exc_info=True)

                if self.config.USE_NN:
                    try:
                        nn_feature_cols = [f for f in self.preprocessor.feature_columns_out if f in X_train_processed.columns]
                        nn_trainer.train(X_train_processed[nn_feature_cols].values, y_train)
                    except ModelError as e:
                        logging.error(f"NN-uudelleenkoulutus epäonnistui askeleella {i}: {e}")
                    except Exception as e:
                        logging.error(f"Odottamaton virhe NN-uudelleenkoulutuksessa: {e}", exc_info=True)

            home_team = current_match.iloc[0]['homeTeamName']
            away_team = current_match.iloc[0]['awayTeamName']
            actual_home_goals = current_match.iloc[0]['homeGoals']
            actual_away_goals = current_match.iloc[0]['awayGoals']

            current_match['elo_home'] = current_match['homeTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)
            current_match['elo_away'] = current_match['awayTeamName'].map(current_elo_ratings).fillna(self.config.INITIAL_ELO)

            try:
                X_predict_processed = self.preprocessor.transform(current_match, df_history_context)
                self.predictor.elo_calculator.elo_ratings = current_elo_ratings
                prediction_result = self.predictor.predict_matches(current_match, X_predict_processed)[0]

                self.results_history.append({
                    'match_index': i,
                    'date': current_match.iloc[0]['utcDate'],
                    'homeTeamName': home_team,
                    'awayTeamName': away_team,
                    'actual_homeGoals': actual_home_goals,
                    'actual_awayGoals': actual_away_goals,
                    'predicted_mu_home': prediction_result.get('mu_home'),
                    'predicted_mu_away': prediction_result.get('mu_away'),
                    'predicted_prob_away': prediction_result.get('probs_1x2', [None]*3)[0],
                    'predicted_prob_draw': prediction_result.get('probs_1x2', [None]*3)[1],
                    'predicted_prob_home': prediction_result.get('probs_1x2', [None]*3)[2],
                    'predicted_prob_over_2_5': prediction_result.get('prob_over_2_5'),
                    'predicted_prob_btts': prediction_result.get('prob_btts'),
                    'model_type': prediction_result.get('model_type')
                })
            except (PreprocessingError, ModelError) as e:
                logging.error(f"Ottelun ennustus epäonnistui askeleella {i} ({home_team} vs {away_team}): {e}")
            except Exception as e:
                logging.error(f"Odottamaton virhe ennustuksessa askeleella {i}: {e}", exc_info=True)

            h_elo, a_elo = current_elo_ratings.get(home_team, self.config.INITIAL_ELO), current_elo_ratings.get(away_team, self.config.INITIAL_ELO)
            new_h_elo, new_a_elo = elo_calculator._update_elo_numba(h_elo, a_elo, int(actual_home_goals), int(actual_away_goals), self.config.K_FACTOR)
            current_elo_ratings[home_team] = new_h_elo
            current_elo_ratings[away_team] = new_a_elo

        logging.info("Jälkitestaus valmis.")
        results_df = pd.DataFrame(self.results_history)
        self.calculate_and_log_metrics(results_df)
        self.plot_results(results_df)
        return results_df

    def calculate_and_log_metrics(self, results_df: pd.DataFrame):
        if results_df.empty:
            logging.warning("Ei voida laskea mittareita: Jälkitestaustulokset tyhjiä.")
            return
        df = results_df.dropna(subset=[
            'actual_homeGoals', 'actual_awayGoals',
            'predicted_mu_home', 'predicted_mu_away',
            'predicted_prob_away', 'predicted_prob_draw', 'predicted_prob_home'
        ]).copy()
        if df.empty:
            logging.warning("Ei validia dataa mittarilaskentaan NaN-poiston jälkeen.")
            return
        df['actual_result'] = np.select(
            [df['actual_homeGoals'] > df['actual_awayGoals'], df['actual_homeGoals'] == df['actual_awayGoals']],
            [2, 1], default=0
        )
        prob_cols = ['predicted_prob_away', 'predicted_prob_draw', 'predicted_prob_home']
        df['predicted_result'] = df[prob_cols].fillna(-1).idxmax(axis=1).map({
            'predicted_prob_away': 0, 'predicted_prob_draw': 1, 'predicted_prob_home': 2
        })
        accuracy = accuracy_score(df['actual_result'], df['predicted_result'])
        mae_home = mean_absolute_error(df['actual_homeGoals'], df['predicted_mu_home'])
        mae_away = mean_absolute_error(df['actual_awayGoals'], df['predicted_mu_away'])
        mae_total = (mae_home + mae_away) / 2.0
        probs = df[prob_cols].values
        epsilon = 1e-6
        probs = np.clip(probs, epsilon, 1.0 - epsilon)
        probs /= probs.sum(axis=1, keepdims=True)
        try:
            logloss = log_loss(df['actual_result'], probs, labels=[0, 1, 2])
        except ValueError as e:
            logging.error(f"Log loss -laskenta epäonnistui: {e}. Tarkista todennäköisyysarvot.")
            logloss = np.nan
        brier = np.mean([
            brier_score_loss(df['actual_result'] == i, probs[:, i]) for i in range(3)
        ])
        logging.info("--- Jälkitestauksen suorituskykymittarit ---")
        logging.info(f"Arvioituja otteluita yhteensä: {len(df)}")
        logging.info(f"1X2-tarkkuus: {accuracy:.3f}")
        logging.info(f"Maalien MAE (keskiarvo koti/vieras): {mae_total:.3f} (Koti: {mae_home:.3f}, Vieras: {mae_away:.3f})")
        logging.info(f"Log Loss: {logloss:.3f}")
        logging.info(f"Brier-pisteet: {brier:.3f}")
        logging.info("------------------------------------")
        metrics = {'matches': len(df), 'accuracy': accuracy, 'mae_total': mae_total,
                   'log_loss': logloss, 'brier_score': brier}
        metrics_path = os.path.join(self.config.prediction_folder, "CSV", f"backtest_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        try:
            with open(metrics_path, 'w') as f:
                json.dump(metrics, f, indent=4)
            logging.info(f"Jälkitestausmittarit tallennettu: {metrics_path}")
        except Exception as e:
            logging.error(f"Mittarien tallennus epäonnistui: {e}")

    def plot_calibration_curve(self, results_df: pd.DataFrame):
        """Piirtää kalibrointikäyrän 1X2-todennäköisyyksille."""
        if results_df.empty or not {'actual_result', 'predicted_prob_away', 'predicted_prob_draw', 'predicted_prob_home'}.issubset(results_df.columns):
            logging.warning("Ohitetaan kalibrointikäyrä: Vaadittava data puuttuu.")
            return

        df = results_df.dropna(subset=['actual_result', 'predicted_prob_away', 'predicted_prob_draw', 'predicted_prob_home']).copy()
        if df.empty:
            logging.warning("Ohitetaan kalibrointikäyrä: Ei validia dataa NaN-poiston jälkeen.")
            return

        df['actual_result'] = df['actual_result'].astype(int)
        actual_results = df['actual_result'].values
        probs = df[['predicted_prob_away', 'predicted_prob_draw', 'predicted_prob_home']].values

        plt.figure(figsize=(10, 8))
        plt.plot([0, 1], [0, 1], "k:", label="Täydellisesti kalibroitu")

        for i, label in enumerate(['Vieraspeli', 'Tasapeli', 'Kotipeli']):
            try:
                y_true_class = (actual_results == i)
                prob_true, prob_pred = calibration_curve(y_true_class, probs[:, i], n_bins=10, strategy='uniform')
                plt.plot(prob_pred, prob_true, "s-", label=f"{label}")
            except ValueError as e:
                logging.error(f"Kalibrointikäyrän laskenta epäonnistui luokalle {i} ({label}): {e}")
            except Exception as e:
                logging.error(f"Odottamaton virhe kalibrointikäyrän piirtämisessä luokalle {i}: {e}", exc_info=True)

        plt.ylabel("Todellinen todennäköisyys")
        plt.xlabel("Ennustettu todennäköisyys")
        plt.ylim([-0.05, 1.05])
        plt.legend(loc="lower right")
        plt.title('Kalibrointikäyrät (luotettavuuskäyrä)')
        plt.grid(True)

        plot_path = os.path.join(self.config.prediction_folder, "PLOTS", f"calibration_curve_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        try:
            plt.savefig(plot_path)
            plt.close()
            logging.info(f"Kalibrointikäyrä tallennettu: {plot_path}")
        except Exception as e:
            logging.error(f"Kalibrointikäyrän tallennus epäonnistui: {e}")

    def plot_feature_importance_bayes(self, bayesian_predictor: BayesianPredictor):
        """Piirtää ominaisuuksien tärkeyden Bayes-mallin jäljestä."""
        if bayesian_predictor.trace is None:
            logging.warning("Ohitetaan Bayes-ominaisuuksien tärkeysplot: Jälkeä ei ole.")
            return

        try:
            beta_vars = [v for v in bayesian_predictor.trace.posterior.data_vars if v.startswith('beta_')]
            if not beta_vars:
                logging.warning("Ei 'beta_'-muuttujia Bayes-jäljestä tärkeysplotille.")
                return

            az.plot_forest(bayesian_predictor.trace, var_names=beta_vars, combined=True, hdi_prob=0.95, figsize=(10, max(5, len(beta_vars)*0.4)))
            plt.title("Bayes-mallin ominaisuuksien tärkeys (posteriorikeskiarvot & 95% HDI)")
            plt.tight_layout()

            plot_path = os.path.join(self.config.prediction_folder, "PLOTS", f"feature_importance_bayes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
            plt.savefig(plot_path)
            plt.close()
            logging.info(f"Bayes-ominaisuuksien tärkeysplot tallennettu: {plot_path}")
        except Exception as e:
            logging.error(f"Bayes-ominaisuuksien tärkeysplotin generointi/tallennus epäonnistui: {e}", exc_info=True)

    def plot_feature_importance_nn(self, nn_predictor: NeuralNetworkPredictor, X_train: pd.DataFrame):
        """Piirtää ominaisuuksien tärkeyden NN-mallille SHAP:lla."""
        if nn_predictor.model is None:
            logging.warning("Ohitetaan NN-ominaisuuksien tärkeysplot: NN-malli ei ole saatavilla.")
            return
        if X_train.empty:
            logging.warning("Ohitetaan NN-ominaisuuksien tärkeysplot: Koulutusdata SHAP-taustalle tyhjä.")
            return

        logging.info("Lasketaan SHAP-arvot NN-ominaisuuksien tärkeydelle...")
        try:
            nn_feature_cols = [f for f in self.preprocessor.feature_columns_out if f in X_train.columns]
            X_train_features = X_train[nn_feature_cols]
            background_data = shap.sample(X_train_features, min(100, X_train_features.shape[0]))

            def predict_fn(data):
                return nn_predictor.model.predict(data)

            explainer = shap.KernelExplainer(predict_fn, background_data)
            shap_values = explainer.shap_values(background_data)

            if isinstance(shap_values, list) and len(shap_values) == 2:
                shap_values_combined = (np.abs(shap_values[0]) + np.abs(shap_values[1])) / 2.0
                output_names = ["Keskim. abs. SHAP (kotimaali)", "Keskim. abs. SHAP (vierasmaali)"]
                shap.summary_plot(shap_values, background_data, feature_names=X_train_features.columns, plot_type="bar", show=False, class_names=output_names)
            else:
                shap_values_combined = shap_values
                plt.figure()
                shap.summary_plot(shap_values_combined, background_data, feature_names=X_train_features.columns, plot_type="bar", show=False)

            plt.title("Neuroverkon ominaisuuksien tärkeys (keskimääräiset absoluuttiset SHAP-arvot)")
            plt.tight_layout()

            plot_path = os.path.join(self.config.prediction_folder, "PLOTS", f"feature_importance_nn_shap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
            plt.savefig(plot_path)
            plt.close()
            logging.info(f"NN SHAP-ominaisuuksien tärkeysplot tallennettu: {plot_path}")
        except ImportError:
            logging.warning("SHAP-kirjastoa ei ole asennettu. Ohitetaan NN-ominaisuuksien tärkeysplot.")
        except Exception as e:
            logging.error(f"NN SHAP-plotin generointi/tallennus epäonnistui: {e}", exc_info=True)

    def plot_results(self, results_df: pd.DataFrame):
        """Generoi plotteja jälkitestaustuloksista."""
        logging.info("Generoidaan jälkitestaustulosten plotteja...")
        self.plot_calibration_curve(results_df)

# --- Raportointimoduuli ---
class Reporter:
    """Käsittelee ennusteraporttien generointia."""

    def __init__(self, config: Config):
        self.config = config

    def generate_csv_report(self, predictions: List[Dict[str, Any]], df_upcoming: pd.DataFrame):
        """Tallentaa ennusteet CSV-tiedostoon."""
        if not predictions:
            logging.warning("Ei ennusteita CSV-raportin generointiin.")
            return
        if df_upcoming.empty or len(predictions) != len(df_upcoming):
            logging.warning(f"Ennusteiden ({len(predictions)}) ja tulevien otteluiden ({len(df_upcoming)}) määrä ei täsmää. Luodaan raportti vain ennusteista.")
            report_df = pd.DataFrame(predictions)
        else:
            report_data = []
            df_upcoming = df_upcoming.reset_index(drop=True)
            for i, pred in enumerate(predictions):
                match_info = df_upcoming.iloc[i]
                report_row = {
                    "match_date": match_info.get('utcDate', pd.NaT).strftime('%Y-%m-%d %H:%M') if pd.notna(match_info.get('utcDate')) else 'N/A',
                    "league": match_info.get('league', 'N/A'),
                    "home_team": pred['homeTeamName'],
                    "away_team": pred['awayTeamName'],
                    "model_type": pred.get('model_type', 'Tuntematon'),
                    "mu_home": f"{pred.get('mu_home', np.nan):.2f}",
                    "mu_away": f"{pred.get('mu_away', np.nan):.2f}",
                    "prob_home": f"{pred.get('probs_1x2', [np.nan]*3)[2]:.3f}",
                    "prob_draw": f"{pred.get('probs_1x2', [np.nan]*3)[1]:.3f}",
                    "prob_away": f"{pred.get('probs_1x2', [np.nan]*3)[0]:.3f}",
                    "prob_over_2_5": f"{pred.get('prob_over_2_5', np.nan):.3f}",
                    "prob_btts": f"{pred.get('prob_btts', np.nan):.3f}",
                    "top_cs_1": list(pred.get('top_correct_scores', {}).keys())[0] if pred.get('top_correct_scores') else "N/A",
                    "top_cs_1_prob": f"{list(pred.get('top_correct_scores', {}).values())[0]:.3f}" if pred.get('top_correct_scores') else "N/A",
                }
                report_data.append(report_row)
            report_df = pd.DataFrame(report_data)

        csv_path = os.path.join(self.config.prediction_folder, "CSV", f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
        try:
            report_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            logging.info(f"Ennusteet tallennettu CSV:hen: {csv_path}")
        except Exception as e:
            logging.error(f"Ennusteiden CSV-tallennus epäonnistui: {e}")

    def generate_text_summary(self, predictions: List[Dict[str, Any]]):
        """Tulostaa ennusteiden tekstiyhteenvedon konsoliin ja lokitiedostoon."""
        if not predictions:
            logging.info("Ei ennusteita yhteenvetoon.")
            return

        logging.info("--- Tämän päivän ennusteiden yhteenveto ---")
        print("\n--- Ennusteiden yhteenveto ---")
        for pred in predictions:
            home = pred['homeTeamName']
            away = pred['awayTeamName']
            p_H = pred.get('probs_1x2', [np.nan]*3)[2]
            p_D = pred.get('probs_1x2', [np.nan]*3)[1]
            p_A = pred.get('probs_1x2', [np.nan]*3)[0]
            mu_H = pred.get('mu_home', np.nan)
            mu_A = pred.get('mu_away', np.nan)
            model = pred.get('model_type', '?')
            top_cs = pred.get('top_correct_scores', {})
            top_cs_str = ", ".join([f"{s} ({p:.1%})" for s, p in top_cs.items()])

            summary_line = (
                f"\n{home} vs {away} ({model})\n"
                f"  Odotetut maalit: {mu_H:.2f} - {mu_A:.2f}\n"
                f"  Todennäköisyydet (1X2): {p_H:.1%} | {p_D:.1%} | {p_A:.1%}\n"
                f"  Yli 2.5 maalia: {pred.get('prob_over_2_5', np.nan):.1%}, Molemmat joukkueet tekevät maalin: {pred.get('prob_btts', np.nan):.1%}\n"
                f"  Todennäköisimmät lopputulokset: {top_cs_str}"
            )
            logging.info(summary_line.replace('\n', ''))
            print(summary_line)

        logging.info("--- Yhteenvedon loppu ---")
        print("--- Yhteenvedon loppu ---\n")

# --- Pääsovelluslogiikka ---
def filter_upcoming_matches(df: pd.DataFrame) -> pd.DataFrame:
    """Suodattaa DataFramen ottelut, jotka on aikataulutettu tälle päivälle tai myöhemmäksi."""
    if df.empty or 'utcDate' not in df.columns:
        return pd.DataFrame()
    df_filtered = df.copy()
    df_filtered['utcDate'] = pd.to_datetime(df_filtered['utcDate'], errors='coerce', utc=True)
    df_filtered = df_filtered.dropna(subset=['utcDate'])
    if df_filtered['utcDate'].dt.tz is not None:
        today = datetime.now(tz=df_filtered['utcDate'].dt.tz).date()
    else:
        today = datetime.now().date()
    return df_filtered[df_filtered['utcDate'].dt.date >= today].sort_values('utcDate')

def filter_most_recent_past_matches(df: pd.DataFrame) -> pd.DataFrame:
    """Suodattaa DataFramen viimeisimmän päivän valmiit ottelut."""
    if df.empty or 'utcDate' not in df.columns or 'status' not in df.columns:
        return pd.DataFrame()
    df_finished = df[df['status'] == 'FINISHED'].copy()
    if df_finished.empty:
        return pd.DataFrame()
    df_finished['utcDate'] = pd.to_datetime(df_finished['utcDate'], errors='coerce', utc=True)
    df_finished = df_finished.dropna(subset=['utcDate'])
    most_recent_date = df_finished['utcDate'].dt.date.max()
    if pd.isna(most_recent_date):
        return pd.DataFrame()
    return df_finished[df_finished['utcDate'].dt.date == most_recent_date].sort_values('utcDate')

def predict_single_match(home_team: str, away_team: str, df_finished: pd.DataFrame,
                        elo_calculator: EloCalculator, preprocessor: FeaturePreprocessor,
                        predictor: MatchPredictor) -> Dict[str, Any]:
    """Ennustaa yksittäisen ottelun ei-interaktiivisesti."""
    match_data = pd.DataFrame([{
        'homeTeamName': home_team,
        'awayTeamName': away_team,
        'utcDate': pd.Timestamp.now(tz='UTC'),
        'homeGoals': np.nan, 'awayGoals': np.nan, 'status': 'SCHEDULED',
        'season': get_current_season(), 'league': Config.DEFAULT_LEAGUE_CODE,
        'elo_home': elo_calculator.get_elo_for_match(home_team, away_team)[0],
        'elo_away': elo_calculator.get_elo_for_match(home_team, away_team)[1]
    }])

    try:
        X_processed = preprocessor.transform(match_data, df_finished)
        result = predictor.predict_matches(match_data, X_processed)[0]
        return result
    except (PreprocessingError, ModelError) as e:
        logging.error(f"Yksittäisen ottelun ennustus epäonnistui: {e}")
        return {}
    except Exception as e:
        logging.error(f"Odottamaton virhe yksittäisen ottelun ennustuksessa: {e}", exc_info=True)
        return {}

def test_run_prediction_pipeline():
    config = Config()
    config.ENABLE_GRADIO_UI = False  # Estä UI:n käynnistys testissä
    config.API_KEY_FOOTBALL_DATA = None
    config.API_KEY_API_FOOTBALL = None
    try:
        run_prediction_pipeline(config, interactive_league=False)
    except DataFetchError:
        pass  # Odotettu, koska API-avaimet puuttuvat
    assert True  # Funktio suoritettiin ilman syntaksivirheitä

def run_prediction_pipeline(config: Config, interactive_league: bool = True):
    """Pääfunktio ennusteputken suorittamiseen."""
    logging.info("--- Aloitetaan ennusteputki ---")

    # Konfiguraation ja asetusten alustus
    config.setup_paths_and_logging()
    config.load_api_keys()

    league_code = config.DEFAULT_LEAGUE_CODE
    league_id = config.DEFAULT_LEAGUE_ID
    if interactive_league:
        try:
            print(f"Nykyinen oletusliiga: {league_code} (ID: {league_id})")
            change = input("Vaihdetaanko liiga? (k/e): ").strip().lower()
            if change == 'k':
                league_code = input(f"Syötä uusi liigakoodi (esim. BL1): ").strip().upper()
                league_id_str = input(f"Syötä uusi liiga-ID (esim. 78): ").strip()
                try:
                    league_id = int(league_id_str)
                except ValueError:
                    print(Fore.RED + "Virheellinen ID, käytetään oletusta.")
                    league_code = config.DEFAULT_LEAGUE_CODE
                    league_id = config.DEFAULT_LEAGUE_ID
            print(f"Käytetään liigaa: {league_code}, ID: {league_id}")
        except Exception as e:
            print(Fore.RED + f"Virhe liigan valinnassa: {e}. Käytetään oletuksia.")
            league_code = config.DEFAULT_LEAGUE_CODE
            league_id = config.DEFAULT_LEAGUE_ID

    # Alusta komponentit
    data_handler = DataHandler(config)
    elo_calculator = EloCalculator(config)
    preprocessor = FeaturePreprocessor(config)
    bayesian_predictor = BayesianPredictor(config)
    nn_predictor = NeuralNetworkPredictor(config)
    predictor = MatchPredictor(config, bayesian_predictor, nn_predictor, elo_calculator)
    evaluator = Evaluator(config, predictor, preprocessor)
    reporter = Reporter(config)

    # Datan haku
    try:
        current_season = get_current_season()
        seasons = [current_season, current_season - 1]  # Hae kaksi viimeisintä kautta
        df_all = data_handler.get_matches(league_code, league_id, seasons)
    except DataFetchError as e:
        logging.critical(f"Kriittinen virhe: Otteludatan haku epäonnistui. {e}")
        return
    except Exception as e:
        logging.critical(f"Odottamaton virhe datan haussa: {e}", exc_info=True)
        return

    if df_all.empty:
        logging.critical("Kriittinen virhe: Ei ladattu otteludataa.")
        return

    df_finished = df_all[df_all['status'] == 'FINISHED'].copy()
    df_upcoming = filter_upcoming_matches(df_all)

    if df_finished.empty:
        logging.critical("Kriittinen virhe: Ei löydy valmiita otteluita datasta. Mallien koulutus ei mahdollista.")
        return

    if df_upcoming.empty:
        logging.warning("Ei tulevia otteluita. Yritetään ennustaa viimeisimmät menneet ottelut.")
        df_predict_target = filter_most_recent_past_matches(df_all)
        if df_predict_target.empty:
            logging.error("Ei tulevia tai viimeisimpiä menneitä otteluita ennustettavaksi.")
            df_predict_target = pd.DataFrame()
    else:
        df_predict_target = df_upcoming

    # ELO-laskenta
    try:
        elo_ratings, elo_history = elo_calculator.calculate_elo_ratings(df_finished, league_code, current_season)
        df_finished['elo_home'] = df_finished['homeTeamName'].map(elo_ratings).fillna(config.INITIAL_ELO)
        df_finished['elo_away'] = df_finished['awayTeamName'].map(elo_ratings).fillna(config.INITIAL_ELO)
        if not df_predict_target.empty:
            df_predict_target['elo_home'] = df_predict_target['homeTeamName'].map(elo_ratings).fillna(config.INITIAL_ELO)
            df_predict_target['elo_away'] = df_predict_target['awayTeamName'].map(elo_ratings).fillna(config.INITIAL_ELO)
    except Exception as e:
        logging.error(f"Virhe ELO-laskennassa: {e}", exc_info=True)
        df_finished['elo_home'] = config.INITIAL_ELO
        df_finished['elo_away'] = config.INITIAL_ELO
        if not df_predict_target.empty:
            df_predict_target['elo_home'] = config.INITIAL_ELO
            df_predict_target['elo_away'] = config.INITIAL_ELO

    # Esikäsittely
    try:
        X_finished_processed = preprocessor.fit_transform(df_finished)
        df_finished_for_bayes = pd.concat([df_finished[['homeTeamName', 'awayTeamName', 'homeGoals', 'awayGoals']], X_finished_processed], axis=1)
        y_finished_for_nn = df_finished[['homeGoals', 'awayGoals']].values
        all_teams = pd.concat([df_finished["homeTeamName"], df_finished["awayTeamName"]]).unique().tolist()
    except (PreprocessingError, ValueError) as e:
        logging.critical(f"Kriittinen virhe esikäsittelyn sovituksessa: {e}", exc_info=True)
        return

    # Mallien koulutus
    try:
        bayesian_predictor.fit(df_finished_for_bayes, all_teams)
        evaluator.plot_feature_importance_bayes(bayesian_predictor)
    except ModelError as e:
        logging.error(f"Lopullinen Bayes-mallin koulutus epäonnistui: {e}")
    except Exception as e:
        logging.error(f"Odottamaton virhe lopullisessa Bayes-koulutuksessa: {e}", exc_info=True)

    if config.USE_NN:
        try:
            nn_feature_cols = [f for f in preprocessor.feature_columns_out if f in X_finished_processed.columns]
            nn_predictor.train(X_finished_processed[nn_feature_cols].values, y_finished_for_nn)
            evaluator.plot_feature_importance_nn(nn_predictor, X_finished_processed[nn_feature_cols])
        except ModelError as e:
            logging.error(f"Lopullinen NN-mallin koulutus epäonnistui: {e}")
        except Exception as e:
            logging.error(f"Odottamaton virhe lopullisessa NN-koulutuksessa: {e}", exc_info=True)

    # Jälkitestaus
    run_backtest_flag = True
    if run_backtest_flag:
        try:
            backtest_results_df = evaluator.run_backtest(df_all, elo_calculator, bayesian_predictor, nn_predictor)
            if not backtest_results_df.empty:
                bt_csv_path = os.path.join(config.prediction_folder, "CSV", f"backtest_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
                backtest_results_df.to_csv(bt_csv_path, index=False, encoding='utf-8-sig')
                logging.info(f"Jälkitestausennusteet tallennettu: {bt_csv_path}")
        except Exception as e:
            logging.error(f"Jälkitestaus epäonnistui: {e}", exc_info=True)
    else:
        logging.info("Ohitetaan jälkitestaus.")

    # Ennusteiden generointi
    if df_predict_target.empty:
        logging.warning("Ei ennustettavia otteluita (tulevia tai viimeisimpiä menneitä).")
    else:
        try:
            X_predict_target_processed = preprocessor.transform(df_predict_target, df_finished)
            predictions = predictor.predict_matches(df_predict_target, X_predict_target_processed)
            reporter.generate_csv_report(predictions, df_predict_target)
            reporter.generate_text_summary(predictions)
        except (PreprocessingError, ModelError) as e:
            logging.error(f"Ennusteiden generointi epäonnistui: {e}", exc_info=True)
        except Exception as e:
            logging.error(f"Odottamaton virhe ennusteiden generoinnissa: {e}", exc_info=True)

    # Gradio UI
    if config.ENABLE_GRADIO_UI:
        try:
            logging.info("Käynnistetään Gradio UI...")
            # Poistetaan vanhat handlerit ja yksinkertaistetaan lokitus konsoliin
            root_logger = logging.getLogger()
            for handler in list(root_logger.handlers):
                root_logger.removeHandler(handler)
            logging.basicConfig(
                level=logging.INFO,
                format="%(asctime)s - %(levelname)s - %(message)s",
                handlers=[logging.StreamHandler(sys.stdout)]
            )

            # Varmistetaan, että uvicorn on asennettu
            import subprocess
            try:
                import uvicorn
            except ImportError:
                subprocess.check_call([sys.executable, "-m", "pip", "install", "uvicorn"])
                import uvicorn

            # Valmistellaan datat Gradio UI:ta varten
            df_finished_for_ui = df_finished.copy()
            teams = sorted(pd.unique(
                pd.concat([df_all["homeTeamName"], df_all["awayTeamName"]])
            ))

            def predict_ui(home: str, away: str) -> str:
                if not home or not away:
                    return "Syötä sekä koti- että vierasjoukkueen nimet."
                df_match = pd.DataFrame([{
                    "homeTeamName": home,
                    "awayTeamName": away,
                    "utcDate": pd.Timestamp.utcnow(),
                    "homeGoals": np.nan, "awayGoals": np.nan, "status": "SCHEDULED",
                    "season": get_current_season(), "league": league_code,
                    "elo_home": elo_calculator.get_elo_for_match(home, away)[0],
                    "elo_away": elo_calculator.get_elo_for_match(home, away)[1]
                }])
                try:
                    X = preprocessor.transform(df_match, df_finished_for_ui)
                    result = predictor.predict_matches(df_match, X)[0]
                    pH, pD, pA = result["probs_1x2"][2], result["probs_1x2"][1], result["probs_1x2"][0]
                    mH, mA = result["mu_home"], result["mu_away"]
                    over25 = result.get("prob_over_2_5", 0.0)
                    btts = result.get("prob_btts", 0.0)
                    scores = "\n".join(f"  {s}: {p:.1%}" for s, p in result.get("top_correct_scores", {}).items())
                    return (
                        f"Ennuste ({result['model_type']}): {home} vs {away}\n"
                        f"Odotetut maalit: {mH:.2f} – {mA:.2f}\n"
                        f"1X2: Kotivoitto {pH:.1%}, Tasapeli {pD:.1%}, Vierasvoitto {pA:.1%}\n"
                        f"Yli 2.5 maalia: {over25:.1%}, BTTS: {btts:.1%}\n"
                        f"Todennäköisimmät lopputulokset:\n{scores}"
                    )
                except Exception as e:
                    logging.error(f"UI-ennustus epäonnistui: {e}", exc_info=True)
                    return f"Virhe ennustuksessa: {e}"

            interface = gr.Interface(
                fn=predict_ui,
                inputs=[
                    gr.Dropdown(choices=teams, label="Kotijoukkue"),
                    gr.Dropdown(choices=teams, label="Vierasjoukkue")
                ],
                outputs=gr.Textbox(label="Ennuste"),
                title="Jalkapallo-ennusteet",
                description=f"Liiga: {league_code}, kausi {current_season}",
                allow_flagging="never"
            )
            interface.launch(server_name="0.0.0.0", server_port=7860, share=False)
        except Exception as e:
            logging.error(f"Gradio UI:n käynnistys epäonnistui: {e}", exc_info=True)

# --- Skriptin suoritus ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Jalkapallo-otteluiden ennustejärjestelmä")
    parser.add_argument("--league_code", type=str, default=Config.DEFAULT_LEAGUE_CODE, help="Liigakoodi (esim. PL, BL1)")
    parser.add_argument("--league_id", type=int, default=Config.DEFAULT_LEAGUE_ID, help="Liiga-ID API-Footballille")
    parser.add_argument("--non_interactive", action="store_true", help="Ohita interaktiivinen liigan valinta")

    if "google.colab" in sys.modules:
        args = parser.parse_args(args=[])
        print("Suoritetaan Google Colab -ympäristössä.")
    else:
        args = parser.parse_args()
        print("Suoritetaan paikallisessa ympäristössä.")

    config = Config()
    config.DEFAULT_LEAGUE_CODE = args.league_code
    config.DEFAULT_LEAGUE_ID = args.league_id

    run_prediction_pipeline(config, interactive_league=not args.non_interactive)

import streamlit as st
st.title("Jalkapallo-ottelun ennusteet")
home_team = st.selectbox("Kotijoukkue", available_teams)
away_team = st.selectbox("Vierasjoukkue", available_teams)
if st.button("Ennusta"):
    result = predict_single_match(home_team, away_team, df_finished, elo_calculator, preprocessor, predictor)
    st.write(result)

"""Alla on yksityiskohtainen suomenkielinen kuvaus annetun jalkapalloennustejärjestelmän koodin rakenteesta ja toiminnasta. Kuvaus on järjestetty selkeästi, jotta se tarjoaa kattavan ymmärryksen koodin tarkoituksesta, organisaatiosta ja toimintavirrasta erityisesti Pythoniin ja koneoppimiseen perehtyneelle lukijalle.

---

## 📖 Koodin yleiskatsaus

Koodi toteuttaa **jalkapallo-otteluiden ennustejärjestelmän**, joka on suunniteltu toimimaan **Google Colab** -ympäristössä. Se hyödyntää ulkoisia rajapintoja (`football-data.org` ja `API-FOOTBALL`) ottelutulosten ennustamiseen. Järjestelmä yhdistää **ELO-pisteytyksen**, **ominaisuuksien luonnin**, **Bayesilaisen mallinnuksen** ja **neuroverkkopohjaisen mallinnuksen** tuottaakseen ennusteita. Lisäksi se sisältää **Gradio-pohjaisen käyttöliittymän** interaktiivisia ennusteita varten. Järjestelmä tukee **walk-forward-jälkitestausta**, **suorituskykymittareita** ja **visualisointeja** mallien tarkkuuden arvioimiseksi.

### Keskeiset ominaisuudet:
- **Datan haku**: Hakee historiallisia ja tulevia ottelutietoja välimuistin avulla.
- **ELO-pisteytys**: Laskee joukkueiden vahvuuden ELO-pisteillä.
- **Ominaisuuksien luonti**: Luo vektoroituja ominaisuuksia, kuten joukkueiden kunto, lepopäivät ja keskinäiset ottelut (H2H).
- **Mallinnus**: Käyttää Bayesilaista (PyMC, Negatiivinen Binomi -jakauma) ja neuroverkkopohjaista (TensorFlow/Keras, Poisson-häviö) mallinnusta sekä ELO-pohjaista varamallia.
- **Arviointi**: Suorittaa walk-forward-jälkitestauksen ja laskee mittareita (tarkkuus, MAE, log loss, Brier-pisteet).
- **Raportointi**: Tuottaa CSV-raportteja, tekstiyhteenvetoja ja visualisointeja (kalibrointikäyrät, ominaisuuksien tärkeys).
- **Käyttöliittymä**: Tarjoaa Gradio-käyttöliittymän interaktiivisia ennusteita varten.

---

## 🏗 Koodin rakenne

Koodi on järjestetty **moduuleihin** (luokat ja funktiot), jotka hoitavat tiettyjä tehtäviä, noudattaen modulaarista ja oliopohjaista suunnittelua. Alla on rakenne jaoteltuna pääkomponentteihin:

### 1. Tuonnit ja riippuvuudet
- **Kirjastot**:
  - **Ydin**: `pandas`, `numpy` datan käsittelyyn; `logging` lokitukseen.
  - **ML/tilastot**: `pymc`, `arviz` Bayesilaiseen mallinnukseen; `tensorflow` neuroverkkoihin; `sklearn` esikäsittelyyn ja mittareihin; `scipy` tilastollisiin jakaumiin; `shap` ominaisuuksien tärkeyden arviointiin.
  - **Rajapinnat**: `requests` HTTP-pyyntöihin; `urllib3` uudelleenyrityksiin.
  - **Aputyökalut**: `tqdm` edistymispalkeille; `matplotlib`, `plotly` visualisointeihin; `colorama` värilliseen konsolitulostukseen; `gradio` käyttöliittymään.
  - **Colab-spesifiset**: `google.colab.drive`, `google.colab.userdata` Google Drive- ja Secrets-integraatioon.
  - **Muut**: `json`, `pickle`, `os`, `sys`, `argparse` tiedostojen käsittelyyn, sarjallistamiseen ja komentoriviargumentteihin.

- **Riippuvuuksien asennus**:
  ```bash
  !pip install python-dotenv pandas numpy pymc arviz tensorflow requests tqdm matplotlib plotly colorama gradio shap joblib
  ```
  Varmistaa, että kaikki tarvittavat kirjastot on asennettu Colab-ympäristöön. `uvicorn`-kirjasto asennetaan dynaamisesti Gradio-käyttöliittymää varten, jos tarpeen.

### 2. Konfiguraatio (`Config`-luokka)
- **Tarkoitus**: Keskittää kaikki konfiguraatioparametrit, polut ja API-avaimien hallinta.
- **Keskeiset attribuutit**:
  - **Mallinnusparametrit**: `SAMPLING_MODE` (Bayesilainen näytteenottotila), `USE_NN` (neuroverkon käyttö), `USE_NEGBIN` (Negatiivinen Binomi -jakauma), `NN_EPOCHS`, `MC_DROPOUT_SAMPLES` jne.
  - **ELO-parametrit**: `K_FACTOR`, `INITIAL_ELO`, `INITIAL_TOP_ELO`, `TOP_TEAMS` (esim. Manchester City, Arsenal).
  - **Dataparametrit**: `DEFAULT_LEAGUE_CODE` (esim. "PL" Premier Leaguelle), `DEFAULT_LEAGUE_ID`, `FEATURE_FORM_WINDOW`, `FEATURE_H2H_WINDOW`, `NUMERIC_FEATURES_TO_SCALE`, `MODEL_FEATURE_COLUMNS`.
  - **Tiedostopolut**: `DRIVE_MOUNT_POINT` (/content/drive), `BASE_DATA_FOLDER` (AI_FUTIS_DATA), `BASE_PREDICTION_FOLDER` (AI_FUTIS_PREDICTIONS), `SUBFOLDERS` (CACHE, PDF, CSV, PLOTS, MODELS).
  - **API-avaimet**: `API_KEY_FOOTBALL_DATA`, `API_KEY_API_FOOTBALL`, `OPENWEATHER_API_KEY` (ladattu Colab Secrets -palvelusta tai ympäristömuuttujista).
  - **Jälkitestaus**: `BACKTEST_TRAIN_SPLIT_RATIO`, `BACKTEST_RETRAIN_STEP`.
  - **Käyttöliittymä**: `ENABLE_GRADIO_UI`.

- **Metodit**:
  - `setup_paths_and_logging()`: Liittää Google Driven, luo hakemistot ja konfiguroi lokituksen kiertävään tiedostoon (`football_predictions.log`) ja konsoliin.
  - `load_api_keys()`: Lataa API-avaimet Colab Secrets -palvelusta tai ympäristömuuttujista, lokittaen onnistumisen tai epäonnistumisen.

- **Toiminnallisuus**:
  - Toimii yhtenä konfiguraation totuuslähteenä.
  - Varmistaa yhtenäiset polut ja lokitus koko järjestelmässä.
  - Hallinnoi API-avaimia turvallisesti Colab Secrets -palvelun kautta.

### 3. Mukautetut poikkeukset
- **Luokat**: `DataFetchError`, `ModelError`, `PreprocessingError`.
- **Tarkoitus**: Tarjoaa erityisiä virhetyyppejä datan haulle, mallien koulutukselle/ennustamiselle ja esikäsittelylle, mahdollistaen kohdennetun virheiden käsittelyn.

### 4. Apufunktiot
- **get_current_season()**:
  - Määrittää nykyisen jalkapallokauden kuukauden perusteella (heinäkuu tai myöhemmin aloittaa uuden kauden).
  - Palauttaa: Kokonaisluku (esim. 2025, jos huhtikuu 2025 ja kuukausi < 7, muuten 2024).

- **get_http_session()**:
  - Luo `requests.Session`-olion uudelleenyrityslogiikalla robusteille API-kutsuille (3 uudelleenyritystä, viivekerroin 0.5, tilakoodit 500, 502, 503, 504).
  - Palauttaa: Konfiguroitu `requests.Session`.

### 5. Datan käsittely (`DataHandler`-luokka)
- **Tarkoitus**: Hakee ja käsittelee ottelutietoja `football-data.org`- ja `API-FOOTBALL`-rajapinnoista välimuistin avulla.
- **Metodit**:
  - `__init__(config)`: Alustaa `Config`-instanssilla ja HTTP-istunnolla.
  - `_fetch_football_data(competition, season)`: Hakee ottelutietoja `football-data.org`:sta tietylle kilpailulle (esim. "PL") ja kaudelle.
    - Käsittelee aikakatkaisuja, HTTP-virheitä ja JSON-dekoodausvirheitä.
    - Palauttaa: `pd.DataFrame` tai `None`, jos haku epäonnistuu.
  - `_fetch_api_football(league_id, season)`: Hakee ottelutietoja `API-FOOTBALL`:sta tietylle liiga-ID:lle ja kaudelle.
    - Kartoittaa API-spesifiset tilakoodit standarditiloiksi (esim. 'FT' → 'FINISHED').
    - Palauttaa: `pd.DataFrame` tai `None`, jos haku epäonnistuu.
  - `get_matches(league_code, league_id, seasons, force_refresh)`: Ohjaa datan hakua useille kausille.
    - Tarkistaa välimuistin (`matches_{league_code}_{season}.pkl`) ja käyttää sitä, jos se on kelvollinen ja ei vanhentunut (`CACHE_EXPIRY_DAYS`).
    - Yrittää ensin `football-data.org`:ia, siirtyy `API-FOOTBALL`:iin, jos se epäonnistuu.
    - Standardoi sarakkeiden nimet (`utcDate`, `status`, `homeTeamName`, `awayTeamName`, `homeGoals`, `awayGoals`, `season`, `league`).
    - Tallentaa haetun datan välimuistiin.
    - Palauttaa: Yhdistetty `pd.DataFrame` kaikista otteluista.

- **Toiminnallisuus**:
  - Käsittelee API-epäonnistumisia robustisti uudelleenyrityksillä ja varamalleilla.
  - Välimuistittaa dataa vähentääkseen API-kutsuja ja parantaakseen suorituskykyä.
  - Varmistaa yhtenäisen dataformaatin eri lähteistä.

### 6. ELO-laskenta (`EloCalculator`-luokka)
- **Tarkoitus**: Laskee joukkueiden ELO-pisteet arvioidakseen niiden suhteellista vahvuutta.
- **Metodit**:
  - `__init__(config)`: Alustaa `Config`-instanssilla, tyhjillä `elo_ratings`- ja `elo_history`-sanakirjoilla sekä ELO-historian tallennuspolulla.
  - `_update_elo_numba(home_elo, away_elo, home_goals, away_goals, k_factor)`: Päivittää ELO-pisteet Numba-optimoinnilla suorituskyvyn parantamiseksi.
    - Laskee odotetun tuloksen ELO-eron perusteella.
    - Päivittää pisteet todellisen ottelutuloksen mukaan (voitto: 1, tasapeli: 0.5, häviö: 0).
    - Palauttaa: Päivitetty `(home_elo, away_elo)`.
  - `calculate_elo_ratings(df_finished, league_code, season)`: Laskee ELO-pisteet kaikille joukkueille päättyneissä otteluissa.
    - Alustaa joukkueet `INITIAL_ELO`:lla (1500) tai `INITIAL_TOP_ELO`:lla (1600 huippujoukkueille, kuten Manchester City).
    - Käy läpi ottelut aikajärjestyksessä, päivittäen ELO-pisteet.
    - Tallentaa ELO-historian pickle-tiedostoon (`elo_history_{league_code}_{season}.pkl`).
    - Palauttaa: `(elo_ratings, elo_history)`-sanakirjat.
  - `get_elo_for_match(home_team, away_team)`: Hakee ELO-pisteet ottelulle, oletusarvoisesti `INITIAL_ELO` tuntemattomille joukkueille.
    - Palauttaa: `(home_elo, away_elo)`.

- **Toiminnallisuus**:
  - Tarjoaa dynaamisen mitan joukkueiden vahvuudelle.
  - Optimoi ELO-päivitykset Numba:lla nopeuden vuoksi.
  - Tallentaa ELO-historian analysointia varten.

### 7. Ominaisuuksien luonti (`FeaturePreprocessor`-luokka)
- **Tarkoitus**: Luo ja esikäsittelee mallinnukseen käytettävät ominaisuudet, kuten joukkueiden kunto, lepopäivät, H2H-tilastot ja johdetut ominaisuudet.
- **Metodit**:
  - `__init__(config)`: Alustaa skaalaimen, imputoijan ja ominaisuussarakkeiden poluilla sekä lataa olemassa olevat esikäsittelijät, jos saatavilla.
  - `_load_preprocessors()`: Lataa tallennetut skaalaimen, imputoijan ja ominaisuussarakkeet levyltä, asettaen `is_fitted` arvoksi `True`, jos onnistuu.
  - `_get_external_data(team, date, data_type)`: Paikkamerkki ulkoiselle datalle (esim. loukkaantumiset, xG, sää), palauttaa oletusarvoja.
  - `_calculate_vectorized_features(df, df_history_for_context)`: Laskee ominaisuudet tehokkaasti vektoroitujen operaatioiden avulla.
    - Käsittelee syötedataframen ja valinnaisen historiallisen kontekstin.
    - Laskee ominaisuuksia, kuten:
      - **Kunto**: Keskimääräinen maaliero viimeisissä `FEATURE_FORM_WINDOW`-otteluissa.
      - **Pisteet per peli (PPG)**: Kumulatiiviset pisteet ja paikkakohtainen PPG.
      - **Lepopäivät**: Päivät edellisestä ottelusta.
      - **H2H**: Keskimääräinen maaliero viimeisissä H2H-otteluissa (`FEATURE_H2H_WINDOW`).
    - Palauttaa: DataFrame laskettujen ominaisuuksien kanssa.
  - `_calculate_h2h_vectorized(df, df_history, h2h_window)`: Laskee H2H-ominaisuudet analysoimalla joukkueiden aiempia kohtaamisia.
    - Luo yksilöllisen `team_pair`-tunnisteen jokaiselle ottelulle.
    - Laskee liukuvan keskiarvon maalierosta, ottaen huomioon koti-/vierasnäkökulman.
    - Palauttaa: DataFrame H2H-ominaisuudella.
  - `fit_transform(df_train)`: Sovittaa esikäsittelijät (imputoija, skaalain) ja muuntaa koulutusdatan.
    - Täyttää puuttuvat arvot nollilla, skaalaa numeeriset ominaisuudet ja rajoittaa arvot (`FEATURE_CLIP_MIN`, `FEATURE_CLIP_MAX`).
    - Laskee johdetut ominaisuudet (`elo_diff`, `form_diff`, `rank_diff`).
    - Tallentaa esikäsittelijät levylle.
    - Palauttaa: Käsitelty DataFrame valituilla mallin ominaisuuksilla.
  - `transform(df, df_ref)`: Soveltaa koulutettuja esikäsittelijöitä uuteen dataan, varmistaen koulutuksen kanssa yhtenäisyyden.
    - Käsittelee puuttuvat ominaisuudet täyttämällä nollilla.
    - Palauttaa: Käsitelty DataFrame mallin ominaisuuksilla.

- **Toiminnallisuus**:
  - Luo kattavan ominaisuusjoukon ennustemallinnukseen.
  - Varmistaa yhtenäisen esikäsittelyn koulutuksen ja ennustuksen välillä.
  - Tallentaa esikäsittelijät uudelleenkäyttöä varten.

### 8. Bayesilainen mallinnus (`BayesianPredictor`-luokka)
- **Tarkoitus**: Toteuttaa Bayesilaisen mallin PyMC:llä ottelutulosten ennustamiseen Negatiivisella Binomi- tai Poisson-jakaumalla.
- **Metodit**:
  - `__init__(config)`: Alustaa jäljen tallennuspolun mallipohjalla ja tyhjillä attribuuteilla jäljelle, joukkueille ja ominaisuussarakkeille.
  - `fit(df_train, teams)`: Kouluttaa Bayesilaisen mallin.
    - Kartoittaa joukkueet indekseihin ja poimii ominaisuudet.
    - Määrittelee PyMC-mallin seuraavilla osilla:
      - **Vakio (intercept)**: Log-maalien keskiarvo.
      - **Hyökkäys/Puolustus**: Joukkuekohtaiset vaikutukset Normaalijakaumalla.
      - **Kotietu**: Joukkuekohtainen vaikutus.
      - **Ominaisuuksien vaikutukset**: Beta-kertoimet ominaisuuksille (esim. `elo_diff`, `h2h`).
      - **Todennäköisyysjakauma**: Negatiivinen Binomi (jos `USE_NEGBIN`) tai Poisson.
    - Näytteistää posteriorin NUTS-menetelmällä (`SAMPLING_PARAMS`) ja tallentaa jäljen NetCDF-muodossa.
    - Lokittaa konvergenssidiagnostiikat (ESS, R-hat, divergenssit).
  - `predict(df_predict)`: Tuottaa ennusteita posteriorinäytteillä.
    - Laskee odotetut maalit (`mu_home`, `mu_away`) jokaiselle ottelulle.
    - Simuloi ottelutuloksia arvioidakseen 1X2-todennäköisyyksiä, yli 2.5 maalin todennäköisyyttä ja molempien joukkueiden maalinteon (BTTS) todennäköisyyttä.
    - Palauttaa: Luettelo ennustesanakirjoista.

- **Toiminnallisuus**:
  - Mallintaa ottelutulokset epävarmuuden kvantifioinnilla.
  - Käsittelee ylidispersioita Negatiivisella Binomi -jakaumalla.
  - Käsittelee uusia joukkueita robustisti varamekanismeilla.

### 9. Neuroverkkopohjainen mallinnus (`NeuralNetworkPredictor`-luokka)
- **Tarkoitus**: Toteuttaa neuroverkon TensorFlow/Kerasilla ottelutulosten ennustamiseen Poisson-häviöllä.
- **Metodit**:
  - `__init__(config)`: Alustaa mallipolulla ja tyhjillä malli- ja syötedimensioattribuuteilla.
  - `build_model(input_dim)`: Rakentaa peräkkäisen neuroverkon.
    - Kerrokset: Syöte, Dense (128, 64, 32 yksikköä, ReLU), BatchNormalization, Dropout (0.3), Dense (2, softplus).
    - Kääntää Adam-optimoijalla ja Poisson-häviöllä.
  - `train(X_train, y_train)`: Kouluttaa mallin varhaisella pysäytyksellä.
    - Validoidaan osajoukolla (`NN_VALIDATION_SPLIT`).
    - Tallentaa koulutetun mallin levylle.
  - `load_model()`: Lataa tallennetun mallin, jos saatavilla.
  - `predict_with_uncertainty(X_predict)`: Ennustaa MC Dropoutilla epävarmuuden arvioimiseksi.
    - Suorittaa useita eteenpäin syöttöjä dropoutin ollessa päällä.
    - Palauttaa: Keskimääräiset ennusteet, keskihajonnat ja näyte-ennusteet.

- **Toiminnallisuus**:
  - Tarjoaa joustavan, epälineaarisen mallin otteluiden ennustamiseen.
  - Sisällyttää epävarmuuden MC Dropoutin kautta.
  - Tallentaa koulutetut mallit uudelleenkäyttöä varten.

### 10. Ennusteiden orkestrointi (`MatchPredictor`-luokka)
- **Tarkoitus**: Koordinoi ennusteita käyttäen neuroverkko-, Bayesilaisia tai ELO-pohjaisia varamalleja.
- **Metodit**:
  - `__init__(config, bayesian_predictor, nn_predictor, elo_calculator)`: Alustaa riippuvuuksilla.
  - `_predict_fallback(home_team, away_team)`: Tuottaa ELO-pohjaisia ennusteita.
    - Käyttää ELO-eroa voitto/tasapeli/häviö-todennäköisyyksien arviointiin.
    - Laskee odotetut maalit ja todennäköisyydet `compute_probabilities`-metodilla.
  - `compute_probabilities(mu_home, mu_away, max_goals, samples)`: Laskee ottelutulosten todennäköisyydet.
    - Näytteistetyille ennusteille (Bayesilainen/NN): Simuloi tuloksia Poisson PMF:llä.
    - Piste-estimaateille (varamalli): Laskee todennäköisyydet suoraan.
    - Palauttaa: 1X2-todennäköisyydet, yli 2.5 maalin todennäköisyys, BTTS-todennäköisyys, yleisimmät lopputulokset.
  - `predict_matches(df_predict, X_predict_processed)`: Tuottaa ennusteita useille otteluille.
    - Kohdistaa indeksit syötedataframen ja käsiteltyjen ominaisuuksien välille.
    - Priorisoi neuroverkkoennusteet (jos `USE_NN` ja onnistunut).
    - Siirtyy Bayesilaisiin ennusteisiin (jos saatavilla).
    - Käyttää ELO-pohjaista varamallia tuntemattomille joukkueille tai epäonnistumisille.
    - Palauttaa: Luettelo ennustesanakirjoista.

- **Toiminnallisuus**:
  - Integroi useita ennustusmenetelmiä selkeällä varastrategialla.
  - Varmistaa robustit ennusteet myös osittaisten mallivikojen tapauksessa.

### 11. Arviointi (`Evaluator`-luokka)
- **Tarkoitus**: Arvioi mallien suorituskykyä walk-forward-jälkitestauksella ja visualisoinneilla.
- **Metodit**:
  - `__init__(config, predictor, preprocessor)`: Alustaa riippuvuuksilla ja tyhjällä tuloshistorialla.
  - `run_backtest(df_all_matches, elo_calculator, bayesian_trainer, nn_trainer)`: Suorittaa walk-forward-jälkitestauksen.
    - Jakaa datan alkukoulutusjoukkoon (`BACKTEST_TRAIN_SPLIT_RATIO`) ja testijoukkoon.
    - Kouluttaa malleja uudelleen joka `BACKTEST_RETRAIN_STEP`-ottelun välein.
    - Tuottaa ennusteita ja lokittaa tulokset.
    - Palauttaa: DataFrame jälkitestaustuloksista.
  - `calculate_and_log_metrics(results_df)`: Laskee suorituskykymittarit.
    - Mittarit: 1X2-tarkkuus, MAE (maalit), log loss, Brier-pisteet.
    - Tallentaa mittarit JSON-tiedostoon.
  - `plot_calibration_curve(results_df)`: Piirtää kalibrointikäyrät 1X2-todennäköisyyksille.
  - `plot_feature_importance_bayes(bayesian_predictor)`: Piirtää ominaisuuksien tärkeyden Bayes-mallille ArviZ:llä.
  - `plot_feature_importance_nn(nn_predictor, X_train)`: Piirtää ominaisuuksien tärkeyden neuroverkolle SHAP:lla.
  - `plot_results(results_df)`: Ohjaa visualisointien luomista.

- **Toiminnallisuus**:
  - Kvantifioi mallien suorituskyvyn useilla dimensioilla.
  - Tarjoaa näkemyksiä ominaisuuksien tärkeydestä ja ennusteiden luotettavuudesta.

### 12. Raportointi (`Reporter`-luokka)
- **Tarkoitus**: Tuottaa ennusteraportteja ja yhteenvetoja.
- **Metodit**:
  - `__init__(config)`: Alustaa `Config`-instanssilla.
  - `generate_csv_report(predictions, df_upcoming)`: Tallentaa ennusteet CSV-tiedostoon.
    - Sisältää ottelutiedot, mallityypin, odotetut maalit, todennäköisyydet ja yleisimmät lopputulokset.
  - `generate_text_summary(predictions)`: Tulostaa ja lokittaa ennusteiden tekstiyhteenvedon.
    - Yksityiskohtia odotetuista maaleista, 1X2-todennäköisyyksistä, yli 2.5 maalin todennäköisyydestä, BTTS:stä ja yleisimmistä lopputuloksista.

- **Toiminnallisuus**:
  - Kommunikoi ennusteet strukturoidussa (CSV) ja ihmisluettavassa (teksti) muodossa.
  - Tukee jälkikäsittelyä ja analyysiä.

### 13. Pääsovelluslogiikka
- **Aputyökalut**:
  - `filter_upcoming_matches(df)`: Suodattaa ottelut, jotka on aikataulutettu tälle päivälle tai myöhemmäksi.
  - `filter_most_recent_past_matches(df)`: Suodattaa viimeisimmän päivän päättyneet ottelut ennustamiseen, jos tulevia otteluita ei ole.
  - `predict_single_match(home_team, away_team, df_finished, elo_calculator, preprocessor, predictor)`: Ennustaa yksittäisen ottelun käyttöliittymää tai testausta varten.
  - `test_run_prediction_pipeline()`: Testaa putken ilman käyttöliittymää tai API-avaimia, varmistaen syntaksivirheiden puuttumisen.

- **Pääfunktio**:
  - `run_prediction_pipeline(config, interactive_league)`: Ohjaa koko ennustetyönkulun:
    1. **Asetukset**: Konfiguroi polut, lokituksen ja API-avaimet.
    2. **Liigan valinta**: Sallii interaktiivisen liigan valinnan tai käyttää oletuksia.
    3. **Komponenttien alustus**: Luo instanssit `DataHandler`, `EloCalculator`, `FeaturePreprocessor`, `BayesianPredictor`, `NeuralNetworkPredictor`, `MatchPredictor`, `Evaluator` ja `Reporter`.
    4. **Datan haku**: Hakee ottelutietoja `DataHandler`:n kautta.
    5. **ELO-laskenta**: Laskee ELO-pisteet päättyneille otteluille ja soveltaa ne ennustekohteisiin.
    6. **Esikäsittely**: Sovittaa esikäsittelijät päättyneille otteluille ja muuntaa ennustekohteet.
    7. **Mallien koulutus**: Kouluttaa Bayesilaiset ja neuroverkkopohjaiset mallit.
    8. **Jälkitestaus**: Suorittaa walk-forward-jälkitestauksen, jos käytössä.
    9. **Ennustus**: Tuottaa ennusteita tuleville tai viimeisimmille otteluille.
    10. **Raportointi**: Tallentaa CSV-raportteja ja tekstiyhteenvetoja.
    11. **Käyttöliittymä**: Käynnistää Gradio-käyttöliittymän interaktiivisia ennusteita varten.

- **Skriptin suoritus**:
  - Käyttää `argparse`:a komentoriviargumenttien käsittelyyn (`league_code`, `league_id`, `non_interactive`).
  - Tunnistaa Colab-ympäristön ja säätää argumenttien parsimisen.
  - Alustaa `Config`-luokan ja suorittaa `run_prediction_pipeline`:n.

---

## 🔄 Toimintavirta

Järjestelmä noudattaa strukturoitua putkea ennusteiden tuottamiseksi:

1. **Alustus**:
   - `Config` konfiguroi polut, lokituksen ja API-avaimet.
   - Komponentit instansioidaan (`DataHandler`, `EloCalculator` jne.).

2. **Datan hankinta**:
   - `DataHandler` hakee ottelutietoja määritetyille kausille, priorisoiden `football-data.org`:ia ja siirtyen `API-FOOTBALL`:iin, jos se epäonnistuu.
   - Data välimuistetaan redundanttien API-kutsujen välttämiseksi.

3. **ELO-laskenta**:
   - `EloCalculator` käsittelee päättyneet ottelut ELO-pisteiden laskemiseksi.
   - Pisteet sovelletaan sekä koulutus- (päättyneet) että ennustedataan (tulevat/viimeiset) dataan.

4. **Ominaisuuksien luonti**:
   - `FeaturePreprocessor` laskee ominaisuudet (kunto, lepopäivät, H2H jne.) koulutus- ja ennustedatalle.
   - Sovittaa esikäsittelijät (imputoija, skaalain) koulutusdataan ja muuntaa sekä koulutus- että ennustedatan.

5. **Mallien koulutus**:
   - `BayesianPredictor` kouluttaa PyMC-mallin joukkuekohtaisilla ja ominaisuusvaikutuksilla.
   - `NeuralNetworkPredictor` kouluttaa Keras-mallin varhaisella pysäytyksellä.

6. **Jälkitestaus**:
   - `Evaluator` suorittaa walk-forward-jälkitestauksen, kouluttaen malleja uudelleen säännöllisesti.
   - Laskee mittarit ja tuottaa visualisointeja.

7. **Ennustus**:
   - `MatchPredictor` tuottaa ennusteita, priorisoiden neuroverkkoa, siirtyen Bayesilaiseen ja käyttäen ELO-pohjaista varamallia tarpeen mukaan.
   - Ennusteet sisältävät odotetut maalit, 1X2-todennäköisyydet, yli 2.5 maalin todennäköisyyden, BTTS:n ja yleisimmät lopputulokset.

8. **Raportointi**:
   - `Reporter` tallentaa ennusteet CSV-tiedostoon ja lokittaa tekstiyhteenvedot.

9. **Käyttöliittymä**:
   - Käynnistää Gradio-käyttöliittymän interaktiivisia ennusteita varten, mahdollistaen joukkueiden valinnan ja tulosten tarkastelun.

---

## 🚀 Toiminnallisuuden yksityiskohdat

### Datan virta
- **Syöte**: Ottelutiedot rajapinnoista, sisältäen `utcDate`, `status`, `homeTeamName`, `awayTeamName`, `homeGoals`, `awayGoals`.
- **Käsittely**:
  - Standardoidaan yhtenäiseen muotoon.
  - Lasketaan ominaisuuksia (esim. `form_home`, `h2h`, `elo_diff`).
  - Esikäsitellään (imputoidaan, skaalataan, rajoitetaan).
- **Tulos**: Ennusteet sanakirjoina, joissa avaimet kuten `mu_home`, `probs_1x2`, `top_correct_scores`.

### Ennustuslogiikka
- **Neuroverkko**: Käyttää syväoppimismallia MC Dropoutilla epävarmuuden arviointiin, ennustaen odotetut maalit.
- **Bayesilainen**: Mallintaa ottelutulokset joukkuekohtaisilla vaikutuksilla ja ominaisuusvaikutuksilla, käyttäen posteriorinäytteitä.
- **Varamalli**: ELO-pohjainen malli robustiuteen, arvioi todennäköisyydet ELO-eroista.

### Arviointi
- **Jälkitestaus**: Simuloi reaalimaailman ennustamista kouluttamalla menneellä datalla ja testaamalla tulevilla otteluilla.
- **Mittarit**: Kvantifioi suorituskyvyn tarkkuudella, MAE:lla, log lossilla ja Brier-pisteillä.
- **Visualisoinnit**: Kalibrointikäyrät ja ominaisuuksien tärkeysplotit tarjoavat näkemyksiä.

### Käyttäjän vuorovaikutus
- **Konsoli**: Interaktiivinen liigan valinta ja tekstiyhteenvedot.
- **Gradio-käyttöliittymä**: Alasvetovalikot joukkueiden valintaan, yksityiskohtaisten ennustetulosten näyttö.

---

## 📌 Keskeiset näkökohdat

- **Robustisuus**: Järjestelmä käsittelee API-epäonnistumisia, puuttuvaa dataa ja tuntemattomia joukkueita varamalleilla.
- **Suorituskyky**: Välimuisti, vektorisoidut operaatiot ja Numba-optimointi parantavat tehokkuutta.
- **Modulaarisuus**: Luokat ovat löyhästi kytkettyjä, mahdollistaen helpon laajennuksen tai korvaamisen.
- **Laajennettavuus**: Ulkoiset tietolähteet (esim. sää, loukkaantumiset) voidaan integroida `_get_external_data`:n kautta.
- **Colab-integraatio**: Hyödyntää Google Drivea tallennukseen ja Colab Secrets -palvelua turvalliseen API-avainten hallintaan.

---

## ❓ Mahdollisia parannuksia

1. **API-avaimien validointi**:
   - Lisää tiukempi tarkistus `run_prediction_pipeline`:en:
     ```python
     if not config.API_KEY_FOOTBALL_DATA and not config.API_KEY_API_FOOTBALL:
         raise ValueError("Vähintään yksi API-avain (football-data.org tai API-FOOTBALL) vaaditaan.")
     ```

2. **H2H-optimointi**:
   - Korvaa iteratiivinen H2H-laskenta vektorisoiduilla operaatioilla:
     ```python
     df_out = df_out.merge(
         h2h_data[['team_pair', 'utcDate', 'h2h']],
         on=['team_pair'],
         how='left'
     )
     df_out['h2h'] = df_out.apply(
         lambda row: row['h2h'] if row['utcDate_y'] < row['utcDate_x'] else 0.0,
         axis=1
     )
     ```

3. **Yksikkötestit**:
   - Lisää testejä `predict_matches`-metodille ja muille kriittisille metodeille luotettavuuden varmistamiseksi.

4. **Streamlit-vaihtoehto**:
   - Jos Gradio-käyttöliittymä epäonnistuu, toteuta Streamlit-käyttöliittymä robustiuden vuoksi:
     ```python
     import streamlit as st
     st.title("Jalkapallo-ottelun ennusteet")
     home_team = st.selectbox("Kotijoukkue", available_teams)
     away_team = st.selectbox("Vierasjoukkue", available_teams)
     if st.button("Ennusta"):
         result = predict_single_match(home_team, away_team, df_finished, elo_calculator, preprocessor, predictor)
         st.write(result)
     ```

---

Tämä yksityiskohtainen kuvaus kattaa koodin rakenteen, komponentit ja toimintavirran suomen kielellä. Jos tarvitset lisäselvityksiä, tiettyjä koodinpätkiä tai apua järjestelmän testaamiseen tai laajentamiseen, kerro minulle! 😊
"""